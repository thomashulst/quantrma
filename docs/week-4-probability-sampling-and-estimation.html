<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title> 4 Week 4: Probability, sampling and estimation13 | Quantitative Research Methods &amp; Analysis</title>
  <meta name="description" content="An introductory textbook for quantitative research methods and data analysis at EUC. This text was adapted from “Answering questions with data” by Matthew J.C. Crump (https://crumplab.github.io/statistics/)" />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content=" 4 Week 4: Probability, sampling and estimation13 | Quantitative Research Methods &amp; Analysis" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="An introductory textbook for quantitative research methods and data analysis at EUC. This text was adapted from “Answering questions with data” by Matthew J.C. Crump (https://crumplab.github.io/statistics/)" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content=" 4 Week 4: Probability, sampling and estimation13 | Quantitative Research Methods &amp; Analysis" />
  
  <meta name="twitter:description" content="An introductory textbook for quantitative research methods and data analysis at EUC. This text was adapted from “Answering questions with data” by Matthew J.C. Crump (https://crumplab.github.io/statistics/)" />
  

<meta name="author" content="Original Author: Matthew J. C. Crump" />
<meta name="author" content="Chapters 2 and 4 adapted from Danielle Navarro" />
<meta name="author" content="Adapted for EUC by Thomas Hulst and Thanos Kostopoulos" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="week-3-correlation-and-causation-adapted3.html"/>
<link rel="next" href="references.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">QuantRMA</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#important-notes"><i class="fa fa-check"></i>Important notes</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#attributions"><i class="fa fa-check"></i>Attributions</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#cc-by-sa-4.0-license"><i class="fa fa-check"></i>CC BY-SA 4.0 license</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="1" data-path="week-1-introductionadapted1.html"><a href="week-1-introductionadapted1.html"><i class="fa fa-check"></i><b>1</b> Week 1: Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="week-1-introductionadapted1.html"><a href="week-1-introductionadapted1.html#the-curse-of-belief-bias"><i class="fa fa-check"></i><b>1.1</b> The curse of belief bias</a></li>
<li class="chapter" data-level="1.2" data-path="week-1-introductionadapted1.html"><a href="week-1-introductionadapted1.html#the-cautionary-tale-of-simpsons-paradox"><i class="fa fa-check"></i><b>1.2</b> The cautionary tale of Simpson’s paradox</a></li>
<li class="chapter" data-level="1.3" data-path="week-1-introductionadapted1.html"><a href="week-1-introductionadapted1.html#statistics-in-psychology-psych"><i class="fa fa-check"></i><b>1.3</b> Statistics in psychology</a></li>
<li class="chapter" data-level="1.4" data-path="week-1-introductionadapted1.html"><a href="week-1-introductionadapted1.html#statistics-in-everyday-life"><i class="fa fa-check"></i><b>1.4</b> Statistics in everyday life</a></li>
<li class="chapter" data-level="1.5" data-path="week-1-introductionadapted1.html"><a href="week-1-introductionadapted1.html#theres-more-to-research-methods-than-statistics"><i class="fa fa-check"></i><b>1.5</b> There’s more to research methods than statistics</a></li>
<li class="chapter" data-level="1.6" data-path="week-1-introductionadapted1.html"><a href="week-1-introductionadapted1.html#a-brief-introduction-to-research-methods"><i class="fa fa-check"></i><b>1.6</b> A brief introduction to research methods</a></li>
<li class="chapter" data-level="1.7" data-path="week-1-introductionadapted1.html"><a href="week-1-introductionadapted1.html#thoughts-measurement"><i class="fa fa-check"></i><b>1.7</b> Some thoughts about measurement</a></li>
<li class="chapter" data-level="1.8" data-path="week-1-introductionadapted1.html"><a href="week-1-introductionadapted1.html#operationalize"><i class="fa fa-check"></i><b>1.8</b> Operationalization: defining your measurement</a></li>
<li class="chapter" data-level="1.9" data-path="week-1-introductionadapted1.html"><a href="week-1-introductionadapted1.html#reliab-valid-measurement"><i class="fa fa-check"></i><b>1.9</b> Assessing the reliability and validity of a measurement</a></li>
<li class="chapter" data-level="1.10" data-path="week-1-introductionadapted1.html"><a href="week-1-introductionadapted1.html#forms-of-measurement-error"><i class="fa fa-check"></i><b>1.10</b> Forms of measurement error</a></li>
<li class="chapter" data-level="1.11" data-path="week-1-introductionadapted1.html"><a href="week-1-introductionadapted1.html#variables"><i class="fa fa-check"></i><b>1.11</b> The role of variables: predictors and outcomes</a></li>
<li class="chapter" data-level="1.12" data-path="week-1-introductionadapted1.html"><a href="week-1-introductionadapted1.html#thats-it-for-this-week"><i class="fa fa-check"></i><b>1.12</b> That’s it for this week</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="week-2-describing-data-adapted2.html"><a href="week-2-describing-data-adapted2.html"><i class="fa fa-check"></i><b>2</b> Week 2: Describing Data</a><ul>
<li class="chapter" data-level="2.1" data-path="week-2-describing-data-adapted2.html"><a href="week-2-describing-data-adapted2.html#scales-of-measurement"><i class="fa fa-check"></i><b>2.1</b> Scales of measurement</a><ul>
<li class="chapter" data-level="2.1.1" data-path="week-2-describing-data-adapted2.html"><a href="week-2-describing-data-adapted2.html#nominal-scale"><i class="fa fa-check"></i><b>2.1.1</b> Nominal scale</a></li>
<li class="chapter" data-level="2.1.2" data-path="week-2-describing-data-adapted2.html"><a href="week-2-describing-data-adapted2.html#ordinal-scale"><i class="fa fa-check"></i><b>2.1.2</b> Ordinal scale</a></li>
<li class="chapter" data-level="2.1.3" data-path="week-2-describing-data-adapted2.html"><a href="week-2-describing-data-adapted2.html#interval-scale"><i class="fa fa-check"></i><b>2.1.3</b> Interval scale</a></li>
<li class="chapter" data-level="2.1.4" data-path="week-2-describing-data-adapted2.html"><a href="week-2-describing-data-adapted2.html#ratio-scale"><i class="fa fa-check"></i><b>2.1.4</b> Ratio scale</a></li>
<li class="chapter" data-level="2.1.5" data-path="week-2-describing-data-adapted2.html"><a href="week-2-describing-data-adapted2.html#continuous-versus-discrete-variables"><i class="fa fa-check"></i><b>2.1.5</b> Continuous versus discrete variables</a></li>
<li class="chapter" data-level="2.1.6" data-path="week-2-describing-data-adapted2.html"><a href="week-2-describing-data-adapted2.html#some-complexities"><i class="fa fa-check"></i><b>2.1.6</b> Some complexities</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="week-2-describing-data-adapted2.html"><a href="week-2-describing-data-adapted2.html#this-is-what-too-many-numbers-looks-like"><i class="fa fa-check"></i><b>2.2</b> This is what too many numbers looks like</a></li>
<li class="chapter" data-level="2.3" data-path="week-2-describing-data-adapted2.html"><a href="week-2-describing-data-adapted2.html#describing-data-using-graphs"><i class="fa fa-check"></i><b>2.3</b> Describing data using graphs</a><ul>
<li class="chapter" data-level="2.3.1" data-path="week-2-describing-data-adapted2.html"><a href="week-2-describing-data-adapted2.html#scatterplot"><i class="fa fa-check"></i><b>2.3.1</b> Scatterplot</a></li>
<li class="chapter" data-level="2.3.2" data-path="week-2-describing-data-adapted2.html"><a href="week-2-describing-data-adapted2.html#histogram"><i class="fa fa-check"></i><b>2.3.2</b> Histogram</a></li>
<li class="chapter" data-level="2.3.3" data-path="week-2-describing-data-adapted2.html"><a href="week-2-describing-data-adapted2.html#other-graphs"><i class="fa fa-check"></i><b>2.3.3</b> Other graphs</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="week-2-describing-data-adapted2.html"><a href="week-2-describing-data-adapted2.html#describing-data-using-numbers"><i class="fa fa-check"></i><b>2.4</b> Describing data using numbers</a></li>
<li class="chapter" data-level="2.5" data-path="week-2-describing-data-adapted2.html"><a href="week-2-describing-data-adapted2.html#measures-of-central-tendency-sameness"><i class="fa fa-check"></i><b>2.5</b> Measures of central tendency (sameness)</a><ul>
<li class="chapter" data-level="2.5.1" data-path="week-2-describing-data-adapted2.html"><a href="week-2-describing-data-adapted2.html#mode"><i class="fa fa-check"></i><b>2.5.1</b> Mode</a></li>
<li class="chapter" data-level="2.5.2" data-path="week-2-describing-data-adapted2.html"><a href="week-2-describing-data-adapted2.html#median"><i class="fa fa-check"></i><b>2.5.2</b> Median</a></li>
<li class="chapter" data-level="2.5.3" data-path="week-2-describing-data-adapted2.html"><a href="week-2-describing-data-adapted2.html#mean"><i class="fa fa-check"></i><b>2.5.3</b> Mean</a></li>
<li class="chapter" data-level="2.5.4" data-path="week-2-describing-data-adapted2.html"><a href="week-2-describing-data-adapted2.html#what-does-the-mean-mean"><i class="fa fa-check"></i><b>2.5.4</b> What does the mean mean?</a></li>
<li class="chapter" data-level="2.5.5" data-path="week-2-describing-data-adapted2.html"><a href="week-2-describing-data-adapted2.html#all-together-now"><i class="fa fa-check"></i><b>2.5.5</b> All together now</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="week-2-describing-data-adapted2.html"><a href="week-2-describing-data-adapted2.html#measures-of-variation-differentness"><i class="fa fa-check"></i><b>2.6</b> Measures of variation (differentness)</a><ul>
<li class="chapter" data-level="2.6.1" data-path="week-2-describing-data-adapted2.html"><a href="week-2-describing-data-adapted2.html#the-range"><i class="fa fa-check"></i><b>2.6.1</b> The range</a></li>
<li class="chapter" data-level="2.6.2" data-path="week-2-describing-data-adapted2.html"><a href="week-2-describing-data-adapted2.html#difference-scores"><i class="fa fa-check"></i><b>2.6.2</b> Difference scores</a></li>
<li class="chapter" data-level="2.6.3" data-path="week-2-describing-data-adapted2.html"><a href="week-2-describing-data-adapted2.html#the-variance"><i class="fa fa-check"></i><b>2.6.3</b> The variance</a></li>
<li class="chapter" data-level="2.6.4" data-path="week-2-describing-data-adapted2.html"><a href="week-2-describing-data-adapted2.html#the-standard-deviation"><i class="fa fa-check"></i><b>2.6.4</b> The standard deviation</a></li>
<li class="chapter" data-level="2.6.5" data-path="week-2-describing-data-adapted2.html"><a href="week-2-describing-data-adapted2.html#closing-thoughts-on-measures-of-variation"><i class="fa fa-check"></i><b>2.6.5</b> Closing thoughts on measures of variation</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="week-2-describing-data-adapted2.html"><a href="week-2-describing-data-adapted2.html#remember-to-look-at-your-data"><i class="fa fa-check"></i><b>2.7</b> Remember to look at your data</a><ul>
<li class="chapter" data-level="2.7.1" data-path="week-2-describing-data-adapted2.html"><a href="week-2-describing-data-adapted2.html#anscombes-quartet"><i class="fa fa-check"></i><b>2.7.1</b> Anscombe’s Quartet</a></li>
<li class="chapter" data-level="2.7.2" data-path="week-2-describing-data-adapted2.html"><a href="week-2-describing-data-adapted2.html#datasaurus-dozen"><i class="fa fa-check"></i><b>2.7.2</b> Datasaurus Dozen</a></li>
</ul></li>
<li class="chapter" data-level="2.8" data-path="week-2-describing-data-adapted2.html"><a href="week-2-describing-data-adapted2.html#thats-it-for-this-week-1"><i class="fa fa-check"></i><b>2.8</b> That’s it for this week</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="week-3-correlation-and-causation-adapted3.html"><a href="week-3-correlation-and-causation-adapted3.html"><i class="fa fa-check"></i><b>3</b> Week 3: Correlation and Causation</a><ul>
<li class="chapter" data-level="3.1" data-path="week-3-correlation-and-causation-adapted3.html"><a href="week-3-correlation-and-causation-adapted3.html#if-something-caused-something-else-to-change-what-would-that-look-like"><i class="fa fa-check"></i><b>3.1</b> If something caused something else to change, what would that look like?</a><ul>
<li class="chapter" data-level="3.1.1" data-path="week-3-correlation-and-causation-adapted3.html"><a href="week-3-correlation-and-causation-adapted3.html#charlie-and-the-chocolate-factory"><i class="fa fa-check"></i><b>3.1.1</b> Charlie and the chocolate factory</a></li>
<li class="chapter" data-level="3.1.2" data-path="week-3-correlation-and-causation-adapted3.html"><a href="week-3-correlation-and-causation-adapted3.html#positive-negative-or-no-correlation"><i class="fa fa-check"></i><b>3.1.2</b> Positive, negative or no correlation</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="week-3-correlation-and-causation-adapted3.html"><a href="week-3-correlation-and-causation-adapted3.html#pearsons-r"><i class="fa fa-check"></i><b>3.2</b> Pearson’s <span class="math inline">\(r\)</span></a><ul>
<li class="chapter" data-level="3.2.1" data-path="week-3-correlation-and-causation-adapted3.html"><a href="week-3-correlation-and-causation-adapted3.html#the-idea-of-covariance"><i class="fa fa-check"></i><b>3.2.1</b> The idea of covariance</a></li>
<li class="chapter" data-level="3.2.2" data-path="week-3-correlation-and-causation-adapted3.html"><a href="week-3-correlation-and-causation-adapted3.html#a-measure-of-covariance"><i class="fa fa-check"></i><b>3.2.2</b> A measure of covariance</a></li>
<li class="chapter" data-level="3.2.3" data-path="week-3-correlation-and-causation-adapted3.html"><a href="week-3-correlation-and-causation-adapted3.html#covariance-formalized"><i class="fa fa-check"></i><b>3.2.3</b> Covariance formalized</a></li>
<li class="chapter" data-level="3.2.4" data-path="week-3-correlation-and-causation-adapted3.html"><a href="week-3-correlation-and-causation-adapted3.html#corrform"><i class="fa fa-check"></i><b>3.2.4</b> <span class="math inline">\(r\)</span> we there yet?</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="week-3-correlation-and-causation-adapted3.html"><a href="week-3-correlation-and-causation-adapted3.html#examples-of-r-with-data"><i class="fa fa-check"></i><b>3.3</b> Examples of <span class="math inline">\(r\)</span> with data</a></li>
<li class="chapter" data-level="3.4" data-path="week-3-correlation-and-causation-adapted3.html"><a href="week-3-correlation-and-causation-adapted3.html#interpreting-correlations"><i class="fa fa-check"></i><b>3.4</b> Interpreting correlations</a><ul>
<li class="chapter" data-level="3.4.1" data-path="week-3-correlation-and-causation-adapted3.html"><a href="week-3-correlation-and-causation-adapted3.html#caus-without-corr"><i class="fa fa-check"></i><b>3.4.1</b> Causation without correlation</a></li>
<li class="chapter" data-level="3.4.2" data-path="week-3-correlation-and-causation-adapted3.html"><a href="week-3-correlation-and-causation-adapted3.html#third-var"><i class="fa fa-check"></i><b>3.4.2</b> Third variables</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="week-3-correlation-and-causation-adapted3.html"><a href="week-3-correlation-and-causation-adapted3.html#relationships-between-variables"><i class="fa fa-check"></i><b>3.5</b> Relationships between variables</a></li>
<li class="chapter" data-level="3.6" data-path="week-3-correlation-and-causation-adapted3.html"><a href="week-3-correlation-and-causation-adapted3.html#establishing-causal-relationships"><i class="fa fa-check"></i><b>3.6</b> Establishing causal relationships</a><ul>
<li class="chapter" data-level="3.6.1" data-path="week-3-correlation-and-causation-adapted3.html"><a href="week-3-correlation-and-causation-adapted3.html#a-frame-of-reference"><i class="fa fa-check"></i><b>3.6.1</b> A frame of reference</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="week-3-correlation-and-causation-adapted3.html"><a href="week-3-correlation-and-causation-adapted3.html#meaningful-comparisons"><i class="fa fa-check"></i><b>3.7</b> Meaningful comparisons</a><ul>
<li class="chapter" data-level="3.7.1" data-path="week-3-correlation-and-causation-adapted3.html"><a href="week-3-correlation-and-causation-adapted3.html#random"><i class="fa fa-check"></i><b>3.7.1</b> Randomization</a></li>
<li class="chapter" data-level="3.7.2" data-path="week-3-correlation-and-causation-adapted3.html"><a href="week-3-correlation-and-causation-adapted3.html#matching"><i class="fa fa-check"></i><b>3.7.2</b> Matching</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="week-3-correlation-and-causation-adapted3.html"><a href="week-3-correlation-and-causation-adapted3.html#taxonomy-of-research-design"><i class="fa fa-check"></i><b>3.8</b> Taxonomy of research design</a></li>
<li class="chapter" data-level="3.9" data-path="week-3-correlation-and-causation-adapted3.html"><a href="week-3-correlation-and-causation-adapted3.html#range-of-research-design"><i class="fa fa-check"></i><b>3.9</b> Range of research design</a><ul>
<li class="chapter" data-level="3.9.1" data-path="week-3-correlation-and-causation-adapted3.html"><a href="week-3-correlation-and-causation-adapted3.html#experimental-designs"><i class="fa fa-check"></i><b>3.9.1</b> Experimental designs</a></li>
<li class="chapter" data-level="3.9.2" data-path="week-3-correlation-and-causation-adapted3.html"><a href="week-3-correlation-and-causation-adapted3.html#longitudinal-designs"><i class="fa fa-check"></i><b>3.9.2</b> Longitudinal designs</a></li>
<li class="chapter" data-level="3.9.3" data-path="week-3-correlation-and-causation-adapted3.html"><a href="week-3-correlation-and-causation-adapted3.html#cross-sectional-designs"><i class="fa fa-check"></i><b>3.9.3</b> Cross-sectional designs</a></li>
</ul></li>
<li class="chapter" data-level="3.10" data-path="week-3-correlation-and-causation-adapted3.html"><a href="week-3-correlation-and-causation-adapted3.html#the-validity-of-your-study"><i class="fa fa-check"></i><b>3.10</b> The validity of your study</a><ul>
<li class="chapter" data-level="3.10.1" data-path="week-3-correlation-and-causation-adapted3.html"><a href="week-3-correlation-and-causation-adapted3.html#internal-validity"><i class="fa fa-check"></i><b>3.10.1</b> Internal validity</a></li>
<li class="chapter" data-level="3.10.2" data-path="week-3-correlation-and-causation-adapted3.html"><a href="week-3-correlation-and-causation-adapted3.html#external-validity"><i class="fa fa-check"></i><b>3.10.2</b> External validity</a></li>
<li class="chapter" data-level="3.10.3" data-path="week-3-correlation-and-causation-adapted3.html"><a href="week-3-correlation-and-causation-adapted3.html#construct-validity"><i class="fa fa-check"></i><b>3.10.3</b> Construct validity</a></li>
</ul></li>
<li class="chapter" data-level="3.11" data-path="week-3-correlation-and-causation-adapted3.html"><a href="week-3-correlation-and-causation-adapted3.html#threats-to-experimental-validity"><i class="fa fa-check"></i><b>3.11</b> Threats to experimental validity</a><ul>
<li class="chapter" data-level="3.11.1" data-path="week-3-correlation-and-causation-adapted3.html"><a href="week-3-correlation-and-causation-adapted3.html#history-effects"><i class="fa fa-check"></i><b>3.11.1</b> History effects</a></li>
<li class="chapter" data-level="3.11.2" data-path="week-3-correlation-and-causation-adapted3.html"><a href="week-3-correlation-and-causation-adapted3.html#maturation-effects"><i class="fa fa-check"></i><b>3.11.2</b> Maturation effects</a></li>
<li class="chapter" data-level="3.11.3" data-path="week-3-correlation-and-causation-adapted3.html"><a href="week-3-correlation-and-causation-adapted3.html#repeated-testing-effects"><i class="fa fa-check"></i><b>3.11.3</b> Repeated testing effects</a></li>
<li class="chapter" data-level="3.11.4" data-path="week-3-correlation-and-causation-adapted3.html"><a href="week-3-correlation-and-causation-adapted3.html#selection-bias"><i class="fa fa-check"></i><b>3.11.4</b> Selection bias</a></li>
<li class="chapter" data-level="3.11.5" data-path="week-3-correlation-and-causation-adapted3.html"><a href="week-3-correlation-and-causation-adapted3.html#diffatt"><i class="fa fa-check"></i><b>3.11.5</b> Differential attrition</a></li>
<li class="chapter" data-level="3.11.6" data-path="week-3-correlation-and-causation-adapted3.html"><a href="week-3-correlation-and-causation-adapted3.html#non-response-bias"><i class="fa fa-check"></i><b>3.11.6</b> Non-response bias</a></li>
<li class="chapter" data-level="3.11.7" data-path="week-3-correlation-and-causation-adapted3.html"><a href="week-3-correlation-and-causation-adapted3.html#regression-to-the-mean"><i class="fa fa-check"></i><b>3.11.7</b> Regression to the mean</a></li>
<li class="chapter" data-level="3.11.8" data-path="week-3-correlation-and-causation-adapted3.html"><a href="week-3-correlation-and-causation-adapted3.html#experimenter-bias"><i class="fa fa-check"></i><b>3.11.8</b> Experimenter bias</a></li>
<li class="chapter" data-level="3.11.9" data-path="week-3-correlation-and-causation-adapted3.html"><a href="week-3-correlation-and-causation-adapted3.html#demand-effects-and-reactivity"><i class="fa fa-check"></i><b>3.11.9</b> Demand effects and reactivity</a></li>
<li class="chapter" data-level="3.11.10" data-path="week-3-correlation-and-causation-adapted3.html"><a href="week-3-correlation-and-causation-adapted3.html#placebo-effects"><i class="fa fa-check"></i><b>3.11.10</b> Placebo effects</a></li>
</ul></li>
<li class="chapter" data-level="3.12" data-path="week-3-correlation-and-causation-adapted3.html"><a href="week-3-correlation-and-causation-adapted3.html#thats-it-for-this-week-2"><i class="fa fa-check"></i><b>3.12</b> That’s it for this week</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="week-4-probability-sampling-and-estimation.html"><a href="week-4-probability-sampling-and-estimation.html"><i class="fa fa-check"></i><b>4</b> Week 4: Probability, sampling and estimation</a><ul>
<li class="chapter" data-level="4.1" data-path="week-4-probability-sampling-and-estimation.html"><a href="week-4-probability-sampling-and-estimation.html#correlation-and-random-chance"><i class="fa fa-check"></i><b>4.1</b> Correlation and random chance</a><ul>
<li class="chapter" data-level="4.1.1" data-path="week-4-probability-sampling-and-estimation.html"><a href="week-4-probability-sampling-and-estimation.html#monte-carlo-simulation-of-random-correlations"><i class="fa fa-check"></i><b>4.1.1</b> Monte-carlo simulation of random correlations</a></li>
<li class="chapter" data-level="4.1.2" data-path="week-4-probability-sampling-and-estimation.html"><a href="week-4-probability-sampling-and-estimation.html#increasing-sample-size-decreases-the-opportunity-for-spurious-correlations"><i class="fa fa-check"></i><b>4.1.2</b> Increasing sample-size decreases the opportunity for spurious correlations</a></li>
<li class="chapter" data-level="4.1.3" data-path="week-4-probability-sampling-and-estimation.html"><a href="week-4-probability-sampling-and-estimation.html#animation-of-no-relationship-between-variables"><i class="fa fa-check"></i><b>4.1.3</b> Animation of no relationship between variables</a></li>
<li class="chapter" data-level="4.1.4" data-path="week-4-probability-sampling-and-estimation.html"><a href="week-4-probability-sampling-and-estimation.html#animation-with-a-relationship-between-variables"><i class="fa fa-check"></i><b>4.1.4</b> Animation with a relationship between variables</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="week-4-probability-sampling-and-estimation.html"><a href="week-4-probability-sampling-and-estimation.html#how-are-probability-and-statistics-different"><i class="fa fa-check"></i><b>4.2</b> How are probability and statistics different?</a></li>
<li class="chapter" data-level="4.3" data-path="week-4-probability-sampling-and-estimation.html"><a href="week-4-probability-sampling-and-estimation.html#what-does-probability-mean"><i class="fa fa-check"></i><b>4.3</b> What does probability mean?</a><ul>
<li class="chapter" data-level="4.3.1" data-path="week-4-probability-sampling-and-estimation.html"><a href="week-4-probability-sampling-and-estimation.html#the-frequentist-view"><i class="fa fa-check"></i><b>4.3.1</b> The frequentist view</a></li>
<li class="chapter" data-level="4.3.2" data-path="week-4-probability-sampling-and-estimation.html"><a href="week-4-probability-sampling-and-estimation.html#the-bayesian-view"><i class="fa fa-check"></i><b>4.3.2</b> The Bayesian view</a></li>
<li class="chapter" data-level="4.3.3" data-path="week-4-probability-sampling-and-estimation.html"><a href="week-4-probability-sampling-and-estimation.html#whats-the-difference-and-who-is-right"><i class="fa fa-check"></i><b>4.3.3</b> What’s the difference? And who is right?</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="week-4-probability-sampling-and-estimation.html"><a href="week-4-probability-sampling-and-estimation.html#basic-probability-theory"><i class="fa fa-check"></i><b>4.4</b> Basic probability theory</a></li>
<li class="chapter" data-level="4.5" data-path="week-4-probability-sampling-and-estimation.html"><a href="week-4-probability-sampling-and-estimation.html#probability-distributions"><i class="fa fa-check"></i><b>4.5</b> Probability distributions</a><ul>
<li class="chapter" data-level="4.5.1" data-path="week-4-probability-sampling-and-estimation.html"><a href="week-4-probability-sampling-and-estimation.html#the-binomial-distribution"><i class="fa fa-check"></i><b>4.5.1</b> The binomial distribution</a></li>
<li class="chapter" data-level="4.5.2" data-path="week-4-probability-sampling-and-estimation.html"><a href="week-4-probability-sampling-and-estimation.html#working-with-the-binomial-distribution-in-r"><i class="fa fa-check"></i><b>4.5.2</b> Working with the binomial distribution in R</a></li>
<li class="chapter" data-level="4.5.3" data-path="week-4-probability-sampling-and-estimation.html"><a href="week-4-probability-sampling-and-estimation.html#the-normal-distribution"><i class="fa fa-check"></i><b>4.5.3</b> The normal distribution</a></li>
<li class="chapter" data-level="4.5.4" data-path="week-4-probability-sampling-and-estimation.html"><a href="week-4-probability-sampling-and-estimation.html#probability-density"><i class="fa fa-check"></i><b>4.5.4</b> Probability density</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="week-4-probability-sampling-and-estimation.html"><a href="week-4-probability-sampling-and-estimation.html#other-useful-distributions"><i class="fa fa-check"></i><b>4.6</b> Other useful distributions</a></li>
<li class="chapter" data-level="4.7" data-path="week-4-probability-sampling-and-estimation.html"><a href="week-4-probability-sampling-and-estimation.html#summary-of-probability"><i class="fa fa-check"></i><b>4.7</b> Summary of Probability</a></li>
<li class="chapter" data-level="4.8" data-path="week-4-probability-sampling-and-estimation.html"><a href="week-4-probability-sampling-and-estimation.html#samples-populations-and-sampling"><i class="fa fa-check"></i><b>4.8</b> Samples, populations and sampling</a><ul>
<li class="chapter" data-level="4.8.1" data-path="week-4-probability-sampling-and-estimation.html"><a href="week-4-probability-sampling-and-estimation.html#defining-a-population"><i class="fa fa-check"></i><b>4.8.1</b> Defining a population</a></li>
<li class="chapter" data-level="4.8.2" data-path="week-4-probability-sampling-and-estimation.html"><a href="week-4-probability-sampling-and-estimation.html#simple-random-samples"><i class="fa fa-check"></i><b>4.8.2</b> Simple random samples</a></li>
<li class="chapter" data-level="4.8.3" data-path="week-4-probability-sampling-and-estimation.html"><a href="week-4-probability-sampling-and-estimation.html#most-samples-are-not-simple-random-samples"><i class="fa fa-check"></i><b>4.8.3</b> Most samples are not simple random samples</a></li>
<li class="chapter" data-level="4.8.4" data-path="week-4-probability-sampling-and-estimation.html"><a href="week-4-probability-sampling-and-estimation.html#how-much-does-it-matter-if-you-dont-have-a-simple-random-sample"><i class="fa fa-check"></i><b>4.8.4</b> How much does it matter if you don’t have a simple random sample?</a></li>
<li class="chapter" data-level="4.8.5" data-path="week-4-probability-sampling-and-estimation.html"><a href="week-4-probability-sampling-and-estimation.html#population-parameters-and-sample-statistics"><i class="fa fa-check"></i><b>4.8.5</b> Population parameters and sample statistics</a></li>
</ul></li>
<li class="chapter" data-level="4.9" data-path="week-4-probability-sampling-and-estimation.html"><a href="week-4-probability-sampling-and-estimation.html#the-law-of-large-numbers"><i class="fa fa-check"></i><b>4.9</b> The law of large numbers</a></li>
<li class="chapter" data-level="4.10" data-path="week-4-probability-sampling-and-estimation.html"><a href="week-4-probability-sampling-and-estimation.html#sampling-distributions-and-the-central-limit-theorem"><i class="fa fa-check"></i><b>4.10</b> Sampling distributions and the central limit theorem</a><ul>
<li class="chapter" data-level="4.10.1" data-path="week-4-probability-sampling-and-estimation.html"><a href="week-4-probability-sampling-and-estimation.html#sampling-distribution-of-the-sample-means"><i class="fa fa-check"></i><b>4.10.1</b> Sampling distribution of the sample means</a></li>
<li class="chapter" data-level="4.10.2" data-path="week-4-probability-sampling-and-estimation.html"><a href="week-4-probability-sampling-and-estimation.html#seeing-the-pieces"><i class="fa fa-check"></i><b>4.10.2</b> Seeing the pieces</a></li>
<li class="chapter" data-level="4.10.3" data-path="week-4-probability-sampling-and-estimation.html"><a href="week-4-probability-sampling-and-estimation.html#sampling-distributions-exist-for-any-sample-statistic"><i class="fa fa-check"></i><b>4.10.3</b> Sampling distributions exist for any sample statistic!</a></li>
</ul></li>
<li class="chapter" data-level="4.11" data-path="week-4-probability-sampling-and-estimation.html"><a href="week-4-probability-sampling-and-estimation.html#the-central-limit-theorem"><i class="fa fa-check"></i><b>4.11</b> The central limit theorem</a></li>
<li class="chapter" data-level="4.12" data-path="week-4-probability-sampling-and-estimation.html"><a href="week-4-probability-sampling-and-estimation.html#z-scores"><i class="fa fa-check"></i><b>4.12</b> z-scores</a><ul>
<li class="chapter" data-level="4.12.1" data-path="week-4-probability-sampling-and-estimation.html"><a href="week-4-probability-sampling-and-estimation.html#idea-behind-z-scores"><i class="fa fa-check"></i><b>4.12.1</b> Idea behind z-scores</a></li>
<li class="chapter" data-level="4.12.2" data-path="week-4-probability-sampling-and-estimation.html"><a href="week-4-probability-sampling-and-estimation.html#calculating-z-scores"><i class="fa fa-check"></i><b>4.12.2</b> Calculating z-scores</a></li>
</ul></li>
<li class="chapter" data-level="4.13" data-path="week-4-probability-sampling-and-estimation.html"><a href="week-4-probability-sampling-and-estimation.html#estimating-population-parameters"><i class="fa fa-check"></i><b>4.13</b> Estimating population parameters</a><ul>
<li class="chapter" data-level="4.13.1" data-path="week-4-probability-sampling-and-estimation.html"><a href="week-4-probability-sampling-and-estimation.html#concrete-population-parameters"><i class="fa fa-check"></i><b>4.13.1</b> Concrete population parameters</a></li>
<li class="chapter" data-level="4.13.2" data-path="week-4-probability-sampling-and-estimation.html"><a href="week-4-probability-sampling-and-estimation.html#abstract-population-parameters"><i class="fa fa-check"></i><b>4.13.2</b> Abstract population parameters</a></li>
<li class="chapter" data-level="4.13.3" data-path="week-4-probability-sampling-and-estimation.html"><a href="week-4-probability-sampling-and-estimation.html#experiments-and-population-parameters"><i class="fa fa-check"></i><b>4.13.3</b> Experiments and Population parameters</a></li>
<li class="chapter" data-level="4.13.4" data-path="week-4-probability-sampling-and-estimation.html"><a href="week-4-probability-sampling-and-estimation.html#interim-summary"><i class="fa fa-check"></i><b>4.13.4</b> Interim summary</a></li>
<li class="chapter" data-level="4.13.5" data-path="week-4-probability-sampling-and-estimation.html"><a href="week-4-probability-sampling-and-estimation.html#estimating-the-population-mean"><i class="fa fa-check"></i><b>4.13.5</b> Estimating the population mean</a></li>
<li class="chapter" data-level="4.13.6" data-path="week-4-probability-sampling-and-estimation.html"><a href="week-4-probability-sampling-and-estimation.html#estimating-the-population-standard-deviation"><i class="fa fa-check"></i><b>4.13.6</b> Estimating the population standard deviation</a></li>
</ul></li>
<li class="chapter" data-level="4.14" data-path="week-4-probability-sampling-and-estimation.html"><a href="week-4-probability-sampling-and-estimation.html#estimating-a-confidence-interval"><i class="fa fa-check"></i><b>4.14</b> Estimating a confidence interval</a><ul>
<li class="chapter" data-level="4.14.1" data-path="week-4-probability-sampling-and-estimation.html"><a href="week-4-probability-sampling-and-estimation.html#a-slight-mistake-in-the-formula"><i class="fa fa-check"></i><b>4.14.1</b> A slight mistake in the formula</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i><b>5</b> References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Quantitative Research Methods &amp; Analysis</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="week-4-probability-sampling-and-estimation" class="section level1">
<h1><span class="header-section-number"> 4</span> Week 4: Probability, sampling and estimation<a href="#fn13" class="footnote-ref" id="fnref13"><sup>13</sup></a></h1>
<blockquote>
<p>I have studied many languages-French, Spanish and a little Italian, but no one told me that Statistics was a foreign language.
—Charmaine J. Forde</p>
</blockquote>
<p>Up to this point in the book, we’ve discussed some of the key ideas in research design, and we’ve talked a little about how you can summarize a data set. To a lot of people, this is all there is to statistics: it’s about calculating averages, collecting all the numbers, drawing graphs, and putting them all in a report somewhere. Kind of like stamp collecting, but with numbers. However, statistics covers much more than that. In fact, descriptive statistics is only a small part of statistics. Another, very useful, part of statistics is that it provides tools <strong>that let you make inferences about data</strong>.</p>
<p>Once you start thinking about statistics in these terms – that statistics is there to help us draw inferences from data – you start seeing examples of it everywhere. For instance, here’s a tiny extract from a newspaper article in the Sydney Morning Herald (30 Oct 2010):</p>
<blockquote>
<p>“I have a tough job” the Premier said in response to a poll which found her government is now the most unpopular Labor administration in polling history, with a primary vote of just 23 per cent.</p>
</blockquote>
<p>This kind of remark is entirely unremarkable in the papers or in everyday life, but let’s have a think about what it entails. A polling company has conducted a survey, usually a pretty big one because they can afford it. I’m too lazy to track down the original survey, so let’s just imagine that they called 1000 voters at random, and 230 (23%) of those claimed that they intended to vote for the party. For the 2010 Federal election, the Australian Electoral Commission reported 4,610,795 enrolled voters in New South Whales; so the opinions of the remaining 4,609,795 voters (about 99.98% of voters) remain unknown to us. Even assuming that no-one lied to the polling company the only thing we can say with confidence is that the true primary vote is somewhere between 230/4610795 (about 0.005%) and 4610025/4610795 (about 99.83%). So, on what basis is it legitimate for the polling company, the newspaper, and the readership to conclude that the Australian Labor Party (ALP) primary vote is about 23%?</p>
<p>The answer to the question is pretty obvious: if I call 1000 people <strong>at random</strong>, and 230 of them say they intend to vote for the ALP, then it seems very unlikely that these are the <strong>only</strong> 230 people out of the entire voting public who actually intend to do so. In other words, we assume that the data collected by the polling company is representative of the population at large. But how representative? Would we be surprised to discover that the true ALP primary vote is actually 24%? 29%? 37%? At this point everyday intuition starts to break down a bit. No-one would be surprised by 24%, and everybody would be surprised by 37%, but it’s a bit hard to say whether 29% is plausible. We need some more powerful tools than just looking at the numbers and guessing. <strong>Inferential statistics</strong> provide the tools that we need to answer these sorts of questions. We will start with looking at how correlations are affected by random chance to build some intuitions about inferential statistics. Then, we discuss in more detail the two building blocks of inferential statistics: 1) probability theory and 2) sampling distributions.</p>
<div id="correlation-and-random-chance" class="section level2">
<h2><span class="header-section-number">4.1</span> Correlation and random chance</h2>
<p>Last week, we discussed several ways in which correlation did not mean causation. For example, we looked at <a href="week-3-correlation-and-causation-adapted3.html#caus-without-corr">causation without correlation</a> and the <a href="week-3-correlation-and-causation-adapted3.html#third-var">third varible problem</a>. However, there is another important important aspect of correlations and that is the fact that they can be produced by random chance. This means that you can find a positive or negative correlation between two measures, when they have absolutely nothing to do with one another. You might have hoped to find zero correlation when two measures are totally unrelated to each other. Although this certainly happens, unrelated measures can produce spurious correlations, just by chance alone.</p>
<p>Let’s demonstrate how correlations can occur by chance when there is no causal connection between two measures. Imagine two participants. One is at the North pole with a lottery machine full of balls with numbers from 1 to 10. The other is at the South pole with a different lottery machine full of balls with numbers from 1 to 10. There are an endless supply of balls in the machine, so every number could be picked for any ball. Each participant randomly chooses 10 balls, then records the number on the ball. In this situation we will assume that there is no possible way that balls chosen by the first participant could causally influence the balls chosen by the second participant. They are on the other side of the world.</p>
<p>Here is what the numbers on each ball could look like for each participant:</p>
<table>
<thead>
<tr class="header">
<th align="right">ball</th>
<th align="right">north_pole</th>
<th align="right">south_pole</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">1</td>
<td align="right">2</td>
<td align="right">4</td>
</tr>
<tr class="even">
<td align="right">2</td>
<td align="right">3</td>
<td align="right">3</td>
</tr>
<tr class="odd">
<td align="right">3</td>
<td align="right">8</td>
<td align="right">8</td>
</tr>
<tr class="even">
<td align="right">4</td>
<td align="right">9</td>
<td align="right">8</td>
</tr>
<tr class="odd">
<td align="right">5</td>
<td align="right">8</td>
<td align="right">6</td>
</tr>
<tr class="even">
<td align="right">6</td>
<td align="right">4</td>
<td align="right">7</td>
</tr>
<tr class="odd">
<td align="right">7</td>
<td align="right">2</td>
<td align="right">9</td>
</tr>
<tr class="even">
<td align="right">8</td>
<td align="right">4</td>
<td align="right">5</td>
</tr>
<tr class="odd">
<td align="right">9</td>
<td align="right">3</td>
<td align="right">7</td>
</tr>
<tr class="even">
<td align="right">10</td>
<td align="right">4</td>
<td align="right">4</td>
</tr>
</tbody>
</table>
<p>In this one case, if we computed Pearson’s <span class="math inline">\(r\)</span>, we would find that <span class="math inline">\(r =\)</span> 0.36. But, we already know that this value does not tell us anything about the relationship between the balls chosen on the North and South pole. We know that the relationship is completely random, because that is how we set up the game.</p>
<p>The better question here is to ask what can random chance do? For example, if we ran our game over and over again thousands of times, each time choosing new balls, and each time computing the correlation, what would we find? The <span class="math inline">\(r\)</span> value will sometimes be positive, sometimes be negative, sometimes be big and sometimes be small. Let’s look at what this random fluctuations would look like. This will give us a window into the kinds of correlations that chance alone can produce.</p>
<div id="monte-carlo-simulation-of-random-correlations" class="section level3">
<h3><span class="header-section-number">4.1.1</span> Monte-carlo simulation of random correlations</h3>
<p>It is possible to use a computer to simulate our game as many times as we want. This process is termed a <a href="https://en.wikipedia.org/wiki/Monte_Carlo_method"><strong>monte-carlo simulation</strong></a>, after the code name for the procedure developped during the <a href="https://www.degruyter.com/view/journals/mcma/22/1/article-p73.xml">Manhattan project</a>.</p>
<p>Below is a script written for R<a href="#fn14" class="footnote-ref" id="fnref14"><sup>14</sup></a>. We won’t go into the details of the code here, you will do more of this during the labs, but let’s briefly explain what is going on. Notice, the part that says <code>for(sim in 1:1000)</code>. This creates a loop that repeats our game 1000 times. Inside the loop there are variables named <code>north_pole</code> and <code>south_pole</code>. During each simulation, we sample 10 random numbers (between 1 to 10) using <code>runif(10,1,10)</code> into each variable. These random numbers stand for the numbers that would have been on the balls from the lottery machine. Once we have 10 random numbers for each, we compute the correlation using <code>cor(north_pole,south_pole)</code>. Then, we save the correlation value and move on to the next simulation. At the end, we will have 1000 individual Pearson <span class="math inline">\(r\)</span> values.</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="week-4-probability-sampling-and-estimation.html#cb12-1"></a><span class="kw">library</span>(ggplot2)</span>
<span id="cb12-2"><a href="week-4-probability-sampling-and-estimation.html#cb12-2"></a>simulated_correlations &lt;-<span class="st"> </span><span class="kw">c</span>() <span class="co"># create empty vector </span></span>
<span id="cb12-3"><a href="week-4-probability-sampling-and-estimation.html#cb12-3"></a><span class="cf">for</span>(sim <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">1000</span>){</span>
<span id="cb12-4"><a href="week-4-probability-sampling-and-estimation.html#cb12-4"></a>  <span class="co"># pick 10 random numbers between 1 and 10 and round the result to the nearest integer</span></span>
<span id="cb12-5"><a href="week-4-probability-sampling-and-estimation.html#cb12-5"></a>  north_pole &lt;-<span class="st"> </span><span class="kw">round</span>(<span class="kw">runif</span>(<span class="dv">10</span>,<span class="dv">1</span>,<span class="dv">10</span>)) </span>
<span id="cb12-6"><a href="week-4-probability-sampling-and-estimation.html#cb12-6"></a>  south_pole &lt;-<span class="st"> </span><span class="kw">round</span>(<span class="kw">runif</span>(<span class="dv">10</span>,<span class="dv">1</span>,<span class="dv">10</span>))</span>
<span id="cb12-7"><a href="week-4-probability-sampling-and-estimation.html#cb12-7"></a>  <span class="co"># save each calculated correlation in the vector</span></span>
<span id="cb12-8"><a href="week-4-probability-sampling-and-estimation.html#cb12-8"></a>  simulated_correlations[sim] &lt;-<span class="st"> </span><span class="kw">cor</span>(north_pole,south_pole) </span>
<span id="cb12-9"><a href="week-4-probability-sampling-and-estimation.html#cb12-9"></a>}</span>
<span id="cb12-10"><a href="week-4-probability-sampling-and-estimation.html#cb12-10"></a></span>
<span id="cb12-11"><a href="week-4-probability-sampling-and-estimation.html#cb12-11"></a><span class="co"># Generate a scatterplot with the simulated correlations</span></span>
<span id="cb12-12"><a href="week-4-probability-sampling-and-estimation.html#cb12-12"></a>sim_df &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">sims=</span><span class="dv">1</span><span class="op">:</span><span class="dv">1000</span>,simulated_correlations)</span>
<span id="cb12-13"><a href="week-4-probability-sampling-and-estimation.html#cb12-13"></a><span class="kw">ggplot</span>(sim_df, <span class="kw">aes</span>(<span class="dt">x =</span> sims, <span class="dt">y =</span> simulated_correlations))<span class="op">+</span></span>
<span id="cb12-14"><a href="week-4-probability-sampling-and-estimation.html#cb12-14"></a><span class="st">  </span><span class="kw">geom_point</span>()<span class="op">+</span></span>
<span id="cb12-15"><a href="week-4-probability-sampling-and-estimation.html#cb12-15"></a><span class="st">  </span><span class="kw">theme_classic</span>()<span class="op">+</span></span>
<span id="cb12-16"><a href="week-4-probability-sampling-and-estimation.html#cb12-16"></a><span class="st">  </span><span class="kw">geom_hline</span>(<span class="dt">yintercept =</span> <span class="dv">-1</span>, <span class="dt">color=</span><span class="st">&quot;red&quot;</span>, <span class="dt">linetype =</span> <span class="dv">2</span>)<span class="op">+</span></span>
<span id="cb12-17"><a href="week-4-probability-sampling-and-estimation.html#cb12-17"></a><span class="st">  </span><span class="kw">geom_hline</span>(<span class="dt">yintercept =</span> <span class="dv">1</span>, <span class="dt">color=</span><span class="st">&quot;red&quot;</span>, <span class="dt">linetype =</span> <span class="dv">2</span>)<span class="op">+</span></span>
<span id="cb12-18"><a href="week-4-probability-sampling-and-estimation.html#cb12-18"></a><span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&quot;Simulation of 1000 r values&quot;</span>)</span></code></pre></div>
<div class="figure"><span id="fig:3anotherthousand"></span>
<img src="quantrma_files/figure-html/3anotherthousand-1.png" alt="Figure showing a range of r-values that can be obtained by chance" width="672" />
<p class="caption">
Figure 4.1: Figure showing a range of r-values that can be obtained by chance
</p>
</div>
<p>Each dot in the scatter plot shows the Pearson <span class="math inline">\(r\)</span> for each simulation from 1 to 1000. As you can see the dots are all over of the place, in between the range -1 to 1. The important lesson here is that random chance produced all of these correlations. This means we can find “correlations” in the data that are completely meaningless, and do not reflect any causal relationship between one measure and another.</p>
<p>Let’s illustrate the idea of finding “random” correlations one more time, with an animation. This time, we will show you a scatter plot of the random values sampled for the balls chosen from the North and South pole. If there is no relationship we should see dots going everywhere. If there happens to be a positive relationship (purely by chance), we should see the dots going from the bottom left to the top right. If there happens to be a negative relationship (purely by chance), we should see the dots going from the top left down to the bottom right.</p>
<p>On more thing to prepare you for the animation. There are three scatter plots below, showing negative, positive, and zero correlations between two variables. You’ve already seen these types of graphs before. We are just reminding you that the blue lines are helpful for seeing the correlation. Negative correlations occur when a line goes down from the top left to bottom right. Positive correlations occur when a line goes up from the bottom left to the top right. Zero correlations occur when the line is flat (doesn’t go up or down).</p>
<div class="figure"><span id="fig:3reminder"></span>
<img src="quantrma_files/figure-html/3reminder-1.png" alt="A reminder of what positive, negative, and zero correlation looks like" width="672" />
<p class="caption">
Figure 4.2: A reminder of what positive, negative, and zero correlation looks like
</p>
</div>
<p>OK, now we are ready for the animation. You are looking at the process of sampling two sets of numbers randomly, one for the X variable (north_pole), and one for the Y variable (south_pole). Each time we sample 10 numbers for each, plot them, then draw a line through them. Remember, these numbers are all completely random, so we should expect, on average that there should be no correlation between the numbers. However, this is not what happens. You can the line going all over the place. Sometimes we find a negative correlation (line goes down), sometimes we see a positive correlation (line goes up), and sometimes it looks like zero correlation (line is more flat).</p>
<div class="figure"><span id="fig:3randcor10gif"></span>
<img src="figures/gifs/corUnifn10-1.gif" alt="Completely random data points drawn from a uniform distribution with a small sample-size of 10. The blue line twirls around sometimes showing large correlations that are produced by chance"  />
<p class="caption">
Figure 4.3: Completely random data points drawn from a uniform distribution with a small sample-size of 10. The blue line twirls around sometimes showing large correlations that are produced by chance
</p>
</div>
<p>You might be thinking this is kind of disturbing. If we know that there should be no correlation between two random variables, how come we are finding correlations? This is a big problem right? I mean, if someone showed me a correlation between two things, and then claimed one thing was related to another, how could know I if it was true? After all, it could be chance!</p>
<p>Fortunately, all is not lost. We can look at our simulated data in another way, using a histogram. Remember, just before the animation, we simulated 1000 different correlations using random numbers. By, putting all of those <span class="math inline">\(r\)</span> values into a histogram, we can get a better sense of how chance behaves. We can see what kind of correlations chance is likely or unlikely to produce. Here is a histogram of the simulated <span class="math inline">\(r\)</span> values.</p>
<div class="figure"><span id="fig:3histrandcor"></span>
<img src="quantrma_files/figure-html/3histrandcor-1.png" alt="A histogram showing the frequency distribution of r-values for completely random values between an X and Y variable (sample-size=10). A full range of r-values can be obtained by chance alone. Larger r-values are less common than smaller r-values" width="672" />
<p class="caption">
Figure 4.4: A histogram showing the frequency distribution of r-values for completely random values between an X and Y variable (sample-size=10). A full range of r-values can be obtained by chance alone. Larger r-values are less common than smaller r-values
</p>
</div>
<p>Notice that this histogram is not flat. Most of the simulated <span class="math inline">\(r\)</span> values are close to zero. Notice, also that the bars get smaller as you move away from zero in the positive or negative direction. The general take home here is that chance can produce a wide range of correlations. However, not all correlations happen very often. For example, the bars for -1 and 1 are very small. Chance does not produce nearly perfect correlations very often. The bars around -.5 and .5 are smaller than the bars around zero, as medium correlations do not occur as often as small correlations by chance alone.</p>
<p>You can think of this histogram as the window of chance. It shows what chance often does, and what it often does not do. If you found a correlation under these very same circumstances (e.g., measured the correlation between two sets of 10 random numbers), then you could consult this window. What should you ask the window? How about, could my observed correlation (the one that you found in your data) have come from this window?</p>
<p>Let’s say you found a correlation of <span class="math inline">\(r = .1\)</span>. Could a .1 have come from the histogram? Well, look at the histogram around where the .1 mark on the x-axis is. Is there a big bar there? If so, this means that chance produces this value fairly often. You might be comfortable with the inference: Yes, this .1 could have been produced by chance, because it is well inside the window of chance.
How about <span class="math inline">\(r = .5\)</span>? The bar is much smaller here, you might think, “well, I can see that chance does produce .5 some times, so chance could have produced my .5. Did it? Maybe, maybe not, not sure”. Here, your confidence in a strong inference about the role of chance might start getting a bit shakier.</p>
<p>How about an <span class="math inline">\(r = .95\)</span>?. You might see that the bar for .95 is very very small, perhaps too small to see. What does this tell you? It tells you that chance does not produce .95 very often, hardly if at all, pretty much never. So, if you found a .95 in your data, what would you infer? Perhaps you would be comfortable inferring that chance did not produce your .95, after all, .95 is mostly outside the window of chance.</p>
</div>
<div id="increasing-sample-size-decreases-the-opportunity-for-spurious-correlations" class="section level3">
<h3><span class="header-section-number">4.1.2</span> Increasing sample-size decreases the opportunity for spurious correlations</h3>
<p>Before moving on, let’s do one more thing with correlations. In our pretend lottery game, each participant only sampled 10 balls each. We found that this could lead to a range of correlations between the numbers randomly drawn from either sides of the pole. Indeed, we even found some correlations that were medium to large in size. If you were a researcher who found such correlations, you might be tempted to believe there was a relationship between your measurements. However, we know in our little game, that those correlations would be spurious, just a product of random sampling<a href="#fn15" class="footnote-ref" id="fnref15"><sup>15</sup></a>.</p>
<p>The good news is that, as a researcher, you get to make the rules of the game. You get to determine how chance can play. This is all still a little bit metaphorical, so let’s make it concrete.</p>
<p>Let’s see what happens in four different scenarios. First, we will repeat what we already did. Each participant will draw 10 balls, then we compute the correlation, and do this over 1000 times and look at a histogram. Second, we will change the game so each participant draws 50 balls each, and then repeat our simulation. Third, and fourth, we will change the game so each participant draws 100 balls each, and then 1000 balls each, and repeat etc.</p>
<p>The graph below shows four different histograms of the Pearson <span class="math inline">\(r\)</span> values in each of the different scenarios. Each scenario involves a different sample-size, from, 10, 50, 100 to 1000.</p>
<div class="figure"><span id="fig:3corrandN"></span>
<img src="quantrma_files/figure-html/3corrandN-1.png" alt="Four histograms showing the frequency distributions of r-values between completely random X and Y variables as a function of sample-size. The width of the distributions shrink as sample-size increases. Smaller sample-sizes are more likely to produce a wider range of r-values by chance. Larger sample-sizes always produce a narrower range of small r-values" width="672" />
<p class="caption">
Figure 4.5: Four histograms showing the frequency distributions of r-values between completely random X and Y variables as a function of sample-size. The width of the distributions shrink as sample-size increases. Smaller sample-sizes are more likely to produce a wider range of r-values by chance. Larger sample-sizes always produce a narrower range of small r-values
</p>
</div>
<p>By inspecting the four histograms you should notice a clear pattern. The width or range of each histogram shrinks as the sample-size increases. What is going on here? Well, we already know that we can think of these histograms as windows of chance. They tell us which <span class="math inline">\(r\)</span> values occur fairly often, which do not. When our sample-size is 10, lots of different <span class="math inline">\(r\)</span> values happen. That histogram is very flat and spread out. However, as the sample-size increases, we see that the window of chance gets pulled in. For example, by the time we get to 1000 balls each, almost all of the Pearson <span class="math inline">\(r\)</span> values are very close to 0.</p>
<p>One take home here, is that increasing sample-size narrows the window of chance. So, for example, if you ran a study involving 1000 samples of two measures, and you found a correlation of .5, then you can clearly see in the bottom right histogram that .5 does not occur very often by chance alone. In fact, there is no bar, because it didn’t happen even once in the simulation. As a result, when you have a large sample size like n = 1000, you might be more confident that your observed correlation (say of .5) was not a spurious correlation. If chance is not producing your result, then something else is.</p>
<p>Finally, notice how your confidence about whether or not chance is mucking about with your results depends on your sample size. If you only obtained 10 samples per measurement, and found <span class="math inline">\(r = .5\)</span>, you should not be as confident that your correlation reflects a real relationship. Instead, you can see that <span class="math inline">\(r\)</span>’s of .5 happen fairly often by chance alone.</p>
<blockquote>
<p>Pro tip: when you run an experiment, under ideal circumstances, you get to decide how many samples you will collect. This means narrowing the window of chance.</p>
</blockquote>
<p>Let’s ingrain these ideas with some more animations. When our sample-size is small (referred to as “n is small”), sampling error can cause all sorts of “patterns” in the data. This makes it possible, and indeed common, for “correlations” to occur between two sets of numbers. When we increase the sample-size, sampling error is reduced, making it less possible for correlations to occur just by chance alone.</p>
</div>
<div id="animation-of-no-relationship-between-variables" class="section level3">
<h3><span class="header-section-number">4.1.3</span> Animation of no relationship between variables</h3>
<p>Below we randomly sample numbers for two variables, plot them, and show the correlation using a line. There are four panels, each showing the number of observations in the samples, from 10, 50, 100, to 1000 in each sample.</p>
<p>Remember, because we are randomly sampling numbers, there should be no relationship between the X and Y variables. But, as we have been discussing, because of chance, we can sometimes observe a correlation (due to chance). The important thing to watch is how the line behaves across the four panels. The line twirls around in all directions when the sample size is 10. It is also moves around quite a bit when the sample size is 50 or 100. It still moves a bit when the sample size is 1000, but much less. In all cases we expect the line to be flat, but sometimes the line shows us a pseudo relationship.</p>
<div class="figure"><span id="fig:3corRandfour"></span>
<img src="figures/gifs/corUnifFourNs-1.gif" alt="Animation of how correlation behaves for completely random X and Y variables as a function of sample size. The best fit line is not very stable for small sample-sizes, but becomes more reliably flat as sample-size increases"  />
<p class="caption">
Figure 4.6: Animation of how correlation behaves for completely random X and Y variables as a function of sample size. The best fit line is not very stable for small sample-sizes, but becomes more reliably flat as sample-size increases
</p>
</div>
<p>Which line should you trust? Well, hopefully you can see that the line for 1000 samples is the most stable. It tends to be very flat every time, and it does not depend so much on the particular sample. The line with 10 observations per sample goes all over the place. The take home here, is that if someone told you that they found a correlation, you should want to know how many observations they had in their sample. If they only had 10 observations, how could you trust the claim that there was a correlation? Not now that you know samples that are that small can do all sorts of things by chance alone. If instead, you found out the sample was very large, then you might trust that finding a little bit more. For example, in the above animation you can see that when there are 1000 samples, we never see a strong or even weak correlation; the line is almost always completely flat. This is because chance almost never produces strong correlations when the sample size is very large.</p>
<p>Let’s look at an animation when there actually is a correlation between variables.</p>
</div>
<div id="animation-with-a-relationship-between-variables" class="section level3">
<h3><span class="header-section-number">4.1.4</span> Animation with a relationship between variables</h3>
<p>Sometimes there are correlations between two variables that are not caused by chance. Below, we get to watch an animation of four scatter plots. Each shows the correlation between two variables. Again, we change the sample-size in steps of 10, 50 100, and 1000. The data have been programmed to contain a real positive correlation. So, we should expect that the line will be going up from the bottom left to the top right. However, there is still variability in the data. So this time, sampling error due to chance will fuzz the correlation. We know it is there, but sometimes chance will cause the correlation to be eliminated.</p>
<p>Notice that in the top left panel (sample-size 10), the line is twirling around much more than the other panels. Every new set of samples produces different correlations. Sometimes, the line even goes flat or downward. However, as we increase sample-size, we can see that the line doesn’t change very much, it is always going up showing a positive correlation.</p>
<div class="figure"><span id="fig:3realcorFour"></span>
<img src="figures/gifs/corRealgif-1.gif" alt="How correlation behaves as a function of sample-size when there is a true correlation between X and Y variables"  />
<p class="caption">
Figure 4.7: How correlation behaves as a function of sample-size when there is a true correlation between X and Y variables
</p>
</div>
<p>The main takeaway here is that even when there is a positive correlation between two things, you might not be able to see it if your sample size is small. For example, you might get unlucky with the one sample that you measured. Your sample could show a negative correlation, even when the actual correlation is positive! Unfortunately, in the real world we usually only have the sample that we collected, so we always have to wonder if we got lucky or unlucky. If you want to remove luck, you need to collect larger samples. Then you will be much more likely to observe the real pattern, rather the a pattern that can be introduced by chance.</p>
<p>This concludes the first part of this chapter: building an intuition about inferential statistics by seeing how random chance underlies our observations. Now, we move on to the two building blocks of inferential statistics: 1) probability theory and 2) sampling distributions.</p>
</div>
</div>
<div id="how-are-probability-and-statistics-different" class="section level2">
<h2><span class="header-section-number">4.2</span> How are probability and statistics different?</h2>
<p>Before we start talking about probability theory in more detail, it’s helpful to spend a moment thinking about the relationship between probability and statistics. The two disciplines are closely related but they’re not identical. Probability theory is “the doctrine of chances”. It’s a branch of mathematics that tells you how often different kinds of events will happen. For example, all of these questions are things you can answer using probability theory:</p>
<ul>
<li>What are the chances of a fair coin coming up heads 10 times in a row?</li>
<li>If I roll two six sided dice, how likely is it that I’ll roll two sixes?</li>
<li>How likely is it that five cards drawn from a perfectly shuffled deck will all be hearts?</li>
<li>What are the chances that I’ll win the lottery?</li>
</ul>
<p>Notice that all of these questions have something in common. In each case the “truth of the world” is known, and my question relates to the “what kind of events” will happen. In the first question I <strong>know</strong> that the coin is fair, so there’s a 50% chance that any individual coin flip will come up heads. In the second question, I <strong>know</strong> that the chance of rolling a 6 on a single die is 1 in 6. In the third question I <strong>know</strong> that the deck is shuffled properly. And in the fourth question, I <strong>know</strong> that the lottery follows specific rules. You get the idea. The critical point is that probabilistic questions start with a known <em>model</em> of the world, and we use that model to do some calculations.</p>
<p>The underlying model can be quite simple. For instance, in the coin flipping example, we can write down the model like this:</p>
<p><span class="math inline">\(P(\mbox{heads}) = 0.5\)</span></p>
<p>which you can read as “the probability of heads is 0.5”. As we’ll see later, in the same way that percentages are numbers that range from 0% to 100%, probabilities are just numbers that range from 0 to 1. When using this probability model to answer the first question, I don’t actually know exactly what’s going to happen. Maybe I’ll get 10 heads, like the question says. But maybe I’ll get three heads. That’s the key thing: in probability theory, the <strong>model</strong> is known, but the <strong>data</strong> are not.</p>
<p>So that’s probability. What about statistics? Statistical questions work the other way around. In statistics, we do not know the truth about the world. All we have is the data, and it is from the data that we want to <strong>learn</strong> the truth about the world. Statistical questions tend to look more like these:</p>
<ul>
<li>If my friend flips a coin 10 times and gets 10 heads, are they playing a trick on me?</li>
<li>If five cards off the top of the deck are all hearts, how likely is it that the deck was shuffled?</li>
<li>If the lottery commissioner’s spouse wins the lottery, how likely is it that the lottery was rigged?</li>
</ul>
<p>This time around, the only thing we have are data. What I <strong>know</strong> is that I saw my friend flip the coin 10 times and it came up heads every time. And what I want to <em>infer</em> is whether or not I should conclude that what I just saw was actually a fair coin being flipped 10 times in a row, or whether I should suspect that my friend is playing a trick on me. The data I have looks like this:</p>
<pre><code>H H H H H H H H H H H</code></pre>
<p>and what I’m trying to do is work out which “model of the world” I should put my trust in. If the coin is fair, then the model I should adopt is one that says that the probability of heads is 0.5; that is, <span class="math inline">\(P(\mbox{heads}) = 0.5\)</span>. If the coin is not fair, then I should conclude that the probability of heads is <strong>not</strong> 0.5, which we would write as <span class="math inline">\(P(\mbox{heads}) \neq 0.5\)</span>. In other words, the statistical inference problem is to figure out which of these probability models is right. Clearly, the statistical question isn’t the same as the probability question, but they’re deeply connected to one another. Because of this, a good introduction to statistical theory will start with a discussion of what probability is and how it works.</p>
</div>
<div id="what-does-probability-mean" class="section level2">
<h2><span class="header-section-number">4.3</span> What does probability mean?</h2>
<p>Let’s start with the first of these questions. What is “probability”? It might seem surprising to you, but while statisticians and mathematicians (mostly) agree on what the <strong>rules</strong> of probability are, there’s much less of a consensus on what the word really <strong>means</strong>. It seems weird because we’re all very comfortable using words like “chance”, “likely”, “possible” and “probable”, and it doesn’t seem like it should be a very difficult question to answer. If you had to explain “probability” to a five year old, you could do a pretty good job. But if you’ve ever had that experience in real life, you might walk away from the conversation feeling like you didn’t quite get it right, and that (like many everyday concepts) it turns out that you don’t <strong>really</strong> know what it’s all about.</p>
<p>So I’ll have a go at it. Let’s suppose I want to bet on a soccer game between two teams of robots, <strong>Arduino Arsenal</strong> and <strong>CPU Milan</strong>. After thinking about it, I decide that there is an 80% probability that <strong>Arduino Arsenal</strong> wins What do I mean by that? Here are three possibilities…</p>
<ul>
<li>They’re robot teams, so I can make them play over and over again, and if I did that, <strong>Arduino Arsenal</strong> would win 8 out of every 10 games on average.</li>
<li>For any given game, I would only agree that betting on this game is “fair” if a $1 bet on <strong>CPU Milan</strong> gives a $5 payoff (i.e. I get my $1 back plus a $4 reward for being correct), as would a $4 bet on <strong>Arduino Arsenal</strong> (i.e., my $4 bet plus a $1 reward).</li>
<li>My subjective “belief” or “confidence” in an <strong>Arduino Arsenal</strong> victory is four times as strong as my belief in a <strong>CPU Milan</strong> victory.</li>
</ul>
<p>Each of these seems sensible. However they’re not identical, and not every statistician would endorse all of them. The reason is that there are different statistical ideologies (yes, really!) and depending on which one you subscribe to, you might say that some of those statements are meaningless or irrelevant. In this section, I give a brief introduction the two main approaches that exist in the literature. These are by no means the only approaches, but they’re the two big ones.</p>
<div id="the-frequentist-view" class="section level3">
<h3><span class="header-section-number">4.3.1</span> The frequentist view</h3>
<p>The first of the two major approaches to probability, and the more dominant one in statistics, is referred to as the <em>frequentist view</em>, and it defines probability as a <em>long-run frequency</em>. Suppose we were to try flipping a fair coin, over and over again. By definition, this is a coin that has <span class="math inline">\(P(H) = 0.5\)</span>. What might we observe? One possibility is that the first 20 flips might look like this:</p>
<pre><code>T,H,H,H,H,T,T,H,H,H,H,T,H,H,T,T,T,T,T,H</code></pre>
<p>In this case 11 of these 20 coin flips (55%) came up heads. Now suppose that I’d been keeping a running tally of the number of heads (which I’ll call <span class="math inline">\(N_H\)</span>) that I’ve seen, across the first <span class="math inline">\(N\)</span> flips, and calculate the proportion of heads <span class="math inline">\(N_H / N\)</span> every time. Here’s what I’d get (I did literally flip coins to produce this!):</p>
<table>
<tbody>
<tr class="odd">
<td align="left">number of flips</td>
<td align="center">1</td>
<td align="center">2</td>
<td align="center">3</td>
<td align="center">4</td>
<td align="center">5</td>
<td align="center">6</td>
<td align="center">7</td>
<td align="center">8</td>
<td align="center">9</td>
<td align="center">10</td>
</tr>
<tr class="even">
<td align="left">number of heads</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">2</td>
<td align="center">3</td>
<td align="center">4</td>
<td align="center">4</td>
<td align="center">4</td>
<td align="center">5</td>
<td align="center">6</td>
<td align="center">7</td>
</tr>
<tr class="odd">
<td align="left">proportion</td>
<td align="center">.00</td>
<td align="center">.50</td>
<td align="center">.67</td>
<td align="center">.75</td>
<td align="center">.80</td>
<td align="center">.67</td>
<td align="center">.57</td>
<td align="center">.63</td>
<td align="center">.67</td>
<td align="center">.70</td>
</tr>
</tbody>
</table>
<table>
<tbody>
<tr class="odd">
<td align="left">number of flips</td>
<td align="center">11</td>
<td align="center">12</td>
<td align="center">13</td>
<td align="center">14</td>
<td align="center">15</td>
<td align="center">16</td>
<td align="center">17</td>
<td align="center">18</td>
<td align="center">19</td>
<td align="center">20</td>
</tr>
<tr class="even">
<td align="left">number of heads</td>
<td align="center">8</td>
<td align="center">8</td>
<td align="center">9</td>
<td align="center">10</td>
<td align="center">10</td>
<td align="center">10</td>
<td align="center">10</td>
<td align="center">10</td>
<td align="center">10</td>
<td align="center">11</td>
</tr>
<tr class="odd">
<td align="left">proportion</td>
<td align="center">.73</td>
<td align="center">.67</td>
<td align="center">.69</td>
<td align="center">.71</td>
<td align="center">.67</td>
<td align="center">.63</td>
<td align="center">.59</td>
<td align="center">.56</td>
<td align="center">.53</td>
<td align="center">.55</td>
</tr>
</tbody>
</table>
<p>Notice that at the start of the sequence, the <strong>proportion</strong> of heads fluctuates wildly, starting at .00 and rising as high as .80. Later on, one gets the impression that it dampens out a bit, with more and more of the values actually being pretty close to the “right” answer of .50. This is the frequentist definition of probability in a nutshell: flip a fair coin over and over again, and as <span class="math inline">\(N\)</span> grows large (approaches infinity, denoted <span class="math inline">\(N\rightarrow \infty\)</span>), the proportion of heads will converge to 50%. There are some subtle technicalities that the mathematicians care about, but qualitatively speaking, that’s how the frequentists define probability. Unfortunately, I don’t have an infinite number of coins, or the infinite patience required to flip a coin an infinite number of times. However, I do have a computer, and computers excel at mindless repetitive tasks. So I asked my computer to simulate flipping a coin 1000 times, and then drew a picture of what happens to the proportion <span class="math inline">\(N_H / N\)</span> as <span class="math inline">\(N\)</span> increases. Actually, I did it four times, just to make sure it wasn’t a fluke. The results are shown in Figure <a href="week-4-probability-sampling-and-estimation.html#fig:4FreqProb">4.8</a>. As you can see, the <strong>proportion of observed heads</strong> eventually stops fluctuating, and settles down; when it does, the number at which it finally settles is (close to) the “true” probability of heads.</p>
<div class="figure"><span id="fig:4FreqProb"></span>
<img src="figures/probability/frequentistProb-eps-converted-to.png" alt="An illustration of how frequentist probability works. If you flip a fair coin over and over again, the proportion of heads that you've seen eventually settles down, and converges to the true probability of 0.5. Each panel shows four different simulated experiments: in each case, we pretend we flipped a coin 1000 times, and kept track of the proportion of flips that were heads as we went along. Although none of these sequences actually ended up with an exact value of .5, if we'd extended the experiment for an infinite number of coin flips they would have." width="1164" />
<p class="caption">
Figure 4.8: An illustration of how frequentist probability works. If you flip a fair coin over and over again, the proportion of heads that you’ve seen eventually settles down, and converges to the true probability of 0.5. Each panel shows four different simulated experiments: in each case, we pretend we flipped a coin 1000 times, and kept track of the proportion of flips that were heads as we went along. Although none of these sequences actually ended up with an exact value of .5, if we’d extended the experiment for an infinite number of coin flips they would have.
</p>
</div>
<p>The frequentist definition of probability has some desirable characteristics. First, it is objective: the probability of an event is <strong>necessarily</strong> grounded in the world. The only way that probability statements can make sense is if they refer to (a sequence of) events that occur in the physical universe. Second, it is unambiguous: any two people watching the same sequence of events unfold, trying to calculate the probability of an event, must inevitably come up with the same answer.</p>
<p>However, it also has undesirable characteristics. Infinite sequences don’t exist in the physical world. For example, suppose you picked up a coin from your pocket and started to flip it. Every time it lands, it impacts on the ground. Each impact wears the coin down a bit; eventually, the coin will be destroyed. So, one might ask whether it really makes sense to pretend that an “infinite” sequence of coin flips is even a meaningful concept, or an objective one. We can’t say that an “infinite sequence” of events is a real thing in the physical universe, because the physical universe doesn’t allow infinite anything.</p>
<p>More seriously, the frequentist definition has a narrow scope. There are lots of things out there that human beings are happy to assign probability to in everyday language, but cannot (even in theory) be mapped onto a hypothetical sequence of events. For instance, if a meteorologist comes on TV and says, “the probability of rain in Adelaide on 2 November 2048 is 60%” we humans are happy to accept this. But it’s not clear how to define this in frequentist terms. There’s only one city of Adelaide, and only one November 2, 2048. There’s no infinite sequence of events here, just a once-off thing. Frequentist probability genuinely <strong>forbids</strong> us from making probability statements about a single event. From the frequentist perspective, it will either rain tomorrow or it will not; there is no “probability” that attaches to a single non-repeatable event. Now, it should be said that there are some very clever tricks that frequentists can use to get around this. One possibility is that what the meteorologist means is something like this: “There is a category of days for which I predict a 60% chance of rain; if we look only across those days for which I make this prediction, then on 60% of those days it will actually rain”. It’s very weird and counterintuitive to think of it this way, but you do see frequentists do this sometimes.</p>
</div>
<div id="the-bayesian-view" class="section level3">
<h3><span class="header-section-number">4.3.2</span> The Bayesian view</h3>
<p>The <strong>Bayesian view</strong> of probability is often called the subjectivist view, and it is a minority view among statisticians, but one that has been steadily gaining traction for the last several decades. There are many flavours of Bayesianism, making hard to say exactly what “the” Bayesian view is. The most common way of thinking about subjective probability is to define the probability of an event as the <strong>degree of belief</strong> that an intelligent and rational agent assigns to that truth of that event. From that perspective, probabilities don’t exist in the world, but rather in the thoughts and assumptions of people and other intelligent beings. However, in order for this approach to work, we need some way of operationalising the “degree of belief”. One way that you can do this is to formalise it in terms of “rational gambling”, though there are many other ways. Suppose that I believe that there’s a 60% probability of rain tomorrow. If someone offers me a bet: if it rains tomorrow, then I win $5, but if it doesn’t rain then I lose $5. Clearly, from my perspective, this is a pretty good bet. On the other hand, if I think that the probability of rain is only 40%, then it’s a bad bet to take. Thus, we can operationalise the notion of a “subjective probability” in terms of what bets I’m willing to accept.</p>
<p>What are the advantages and disadvantages to the Bayesian approach? The main advantage is that it allows you to assign probabilities to any event you want to. You don’t need to be limited to those events that are repeatable. The main disadvantage (to many people) is that we can’t be purely objective – specifying a probability requires us to specify an entity that has the relevant degree of belief. This entity might be a human, an alien, a robot, or even a statistician, but there has to be an intelligent agent out there that believes in things. To many people this is uncomfortable: it seems to make probability arbitrary. While the Bayesian approach does require that the agent in question be rational (i.e., obey the rules of probability), it does allow everyone to have their own beliefs; I can believe the coin is fair and you don’t have to, even though we’re both rational. The frequentist view doesn’t allow any two observers to attribute different probabilities to the same event: when that happens, then at least one of them must be wrong. The Bayesian view does not prevent this from occurring. Two observers with different background knowledge can legitimately hold different beliefs about the same event. In short, where the frequentist view is sometimes considered to be too narrow (forbids lots of things that that we want to assign probabilities to), the Bayesian view is sometimes thought to be too broad (allows too many differences between observers).</p>
</div>
<div id="whats-the-difference-and-who-is-right" class="section level3">
<h3><span class="header-section-number">4.3.3</span> What’s the difference? And who is right?</h3>
<p>Now that you’ve seen each of these two views independently, it’s useful to make sure you can compare the two. Go back to the hypothetical robot soccer game at the start of the section. What do you think a frequentist and a Bayesian would say about these three statements? Which statement would a frequentist say is the correct definition of probability? Which one would a Bayesian do? Would some of these statements be meaningless to a frequentist or a Bayesian? If you’ve understood the two perspectives, you should have some sense of how to answer those questions.</p>
<p>Okay, assuming you understand the difference, you might be wondering which of them is <strong>right</strong>? Honestly, I don’t know that there is a right answer. As far as I can tell there’s nothing mathematically incorrect about the way frequentists think about sequences of events, and there’s nothing mathematically incorrect about the way that Bayesians define the beliefs of a rational agent. In fact, when you dig down into the details, Bayesians and frequentists actually agree about a lot of things. Many frequentist methods lead to decisions that Bayesians agree a rational agent would make. Many Bayesian methods have very good frequentist properties.</p>
<p>For the most part, I’m a pragmatist so I’ll use any statistical method that I trust. As it turns out, that makes me prefer Bayesian methods, but I’m not fundamentally opposed to frequentist methods. Not everyone is quite so relaxed. For instance, consider Sir Ronald Fisher, a vehement opponent to all things Bayesian, whose paper on the mathematical foundations of statistics referred to Bayesian probability as “an impenetrable jungle [that] arrests progress towards precision of statistical concepts” <span class="citation">Fisher (<a href="#ref-fisher_interpretation_1922" role="doc-biblioref">1922</a>, 311)</span>. Or the psychologist Paul Meehl, who suggests that relying on frequentist methods could turn you into “a potent but sterile intellectual rake who leaves in his merry path a long train of ravished maidens but no viable scientific offspring” <span class="citation">Meehl (<a href="#ref-meehl_theory_1967" role="doc-biblioref">1967</a>, 114)</span>. The history of statistics, as you might gather, is not devoid of entertainment.</p>
</div>
</div>
<div id="basic-probability-theory" class="section level2">
<h2><span class="header-section-number">4.4</span> Basic probability theory</h2>
<p>Ideological arguments between Bayesians and frequentists notwithstanding, it turns out that people mostly agree on the rules that probabilities should obey. There are lots of different ways of arriving at these rules. The most commonly used approach is based on the work of Andrey Kolmogorov, one of the great Soviet mathematicians of the 20th century. I won’t go into a lot of detail, but I’ll try to give you a bit of a sense of how it works. And in order to do so, I’m going to have to talk about my pants.</p>
<p>One of the disturbing truths about my life is that I only own 5 pairs of pants: three pairs of jeans, the bottom half of a suit, and a pair of tracksuit pants. Even sadder, I’ve given them names: I call them <span class="math inline">\(X_1\)</span>, <span class="math inline">\(X_2\)</span>, <span class="math inline">\(X_3\)</span>, <span class="math inline">\(X_4\)</span> and <span class="math inline">\(X_5\)</span>. I really do: that’s why they call me Mister Imaginative. Now, on any given day, I pick out exactly one of pair of pants to wear. Not even I’m so stupid as to try to wear two pairs of pants, and thanks to years of training I never go outside without wearing pants anymore. If I were to describe this situation using the language of probability theory, I would refer to each pair of pants (i.e., each <span class="math inline">\(X\)</span>) as an <em>elementary event</em>. The key characteristic of elementary events is that every time we make an observation (e.g., every time I put on a pair of pants), then the outcome will be one and only one of these events. Like I said, these days I always wear exactly one pair of pants, so my pants satisfy this constraint. Similarly, the set of all possible events is called a <em>sample space</em>. Granted, some people would call it a “wardrobe”, but that’s because they’re refusing to think about my pants in probabilistic terms. Sad.</p>
<p>Okay, now that we have a sample space (a wardrobe), which is built from lots of possible elementary events (pants), what we want to do is assign a <em>probability</em> to one of these elementary events. For an event <span class="math inline">\(X\)</span>, the probability of that event <span class="math inline">\(P(X)\)</span> is a number that lies between 0 and 1. The bigger the value of <span class="math inline">\(P(X)\)</span>, the more likely the event is to occur. So, for example, if <span class="math inline">\(P(X) = 0\)</span>, it means the event <span class="math inline">\(X\)</span> is impossible (i.e., I never wear those pants). On the other hand, if <span class="math inline">\(P(X) = 1\)</span> it means that event <span class="math inline">\(X\)</span> is certain to occur (i.e., I always wear those pants). For probability values in the middle, it means that I sometimes wear those pants. For instance, if <span class="math inline">\(P(X) = 0.5\)</span> it means that I wear those pants half of the time.</p>
<p>At this point, we’re almost done. The last thing we need to recognise is that “something always happens”. Every time I put on pants, I really do end up wearing pants (crazy, right?). What this somewhat trite statement means, in probabilistic terms, is that the probabilities of the elementary events need to add up to 1. This is known as the <em>law of total probability</em>, not that any of us really care. More importantly, if these requirements are satisfied, then what we have is a <em>probability distribution</em>. For example, this is an example of a probability distribution</p>
<table>
<thead>
<tr class="header">
<th align="left">Which pants?</th>
<th align="center">Label</th>
<th align="center">Probability</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Blue jeans</td>
<td align="center"><span class="math inline">\(X_1\)</span></td>
<td align="center"><span class="math inline">\(P(X_1) = .5\)</span></td>
</tr>
<tr class="even">
<td align="left">Grey jeans</td>
<td align="center"><span class="math inline">\(X_2\)</span></td>
<td align="center"><span class="math inline">\(P(X_2) = .3\)</span></td>
</tr>
<tr class="odd">
<td align="left">Black jeans</td>
<td align="center"><span class="math inline">\(X_3\)</span></td>
<td align="center"><span class="math inline">\(P(X_3) = .1\)</span></td>
</tr>
<tr class="even">
<td align="left">Black suit</td>
<td align="center"><span class="math inline">\(X_4\)</span></td>
<td align="center"><span class="math inline">\(P(X_4) = 0\)</span></td>
</tr>
<tr class="odd">
<td align="left">Blue tracksuit</td>
<td align="center"><span class="math inline">\(X_5\)</span></td>
<td align="center"><span class="math inline">\(P(X_5) = .1\)</span></td>
</tr>
</tbody>
</table>
<p>Each of the events has a probability that lies between 0 and 1, and if we add up the probability of all events, they sum to 1. Awesome. We can even draw a nice bar graph to visualise this distribution, as shown in Figure <a href="week-4-probability-sampling-and-estimation.html#fig:pantsprob">4.9</a>. And at this point, we’ve all achieved something. You’ve learned what a probability distribution is, and I’ve finally managed to find a way to create a graph that focuses entirely on my pants. Everyone wins!</p>
<div class="figure"><span id="fig:pantsprob"></span>
<img src="quantrma_files/figure-html/pantsprob-1.png" alt="A visual depiction of the &quot;pants&quot; probability distribution. There are five &quot;elementary events&quot;, corresponding to the five pairs of pants that I own. Each event has some probability of occurring: this probability is a number between 0 to 1. The sum of these probabilities is 1." width="672" />
<p class="caption">
Figure 4.9: A visual depiction of the “pants” probability distribution. There are five “elementary events”, corresponding to the five pairs of pants that I own. Each event has some probability of occurring: this probability is a number between 0 to 1. The sum of these probabilities is 1.
</p>
</div>
<p>The only other thing that I need to point out is that probability theory allows you to talk about <em>non elementary events</em> as well as elementary ones. The easiest way to illustrate the concept is with an example. In the pants example, it’s perfectly legitimate to refer to the probability that I wear jeans. In this scenario, the “Thomas wears jeans” event said to have happened as long as the elementary event that actually did occur is one of the appropriate ones; in this case “blue jeans”, “black jeans” or “grey jeans”. In mathematical terms, we defined the “jeans” event <span class="math inline">\(E\)</span> to correspond to the set of elementary events <span class="math inline">\((X_1, X_2, X_3)\)</span>. If any of these elementary events occurs, then <span class="math inline">\(E\)</span> is also said to have occurred. Having decided to write down the definition of the <span class="math inline">\(E\)</span> this way, it’s pretty straightforward to state what the probability <span class="math inline">\(P(E)\)</span> is: we just add everything up. In this particular case <span class="math display">\[P(E) = P(X_1) + P(X_2) + P(X_3)\]</span> and, since the probabilities of blue, grey and black jeans respectively are .5, .3 and .1, the probability that I wear jeans is equal to .9.</p>
<p>At this point you might be thinking that this is all terribly obvious and simple and you’d be right. All we’ve really done is wrap some basic mathematics around a few common sense intuitions. However, from these simple beginnings it’s possible to construct some extremely powerful mathematical tools. I’m definitely not going to go into the details in this book, but what I will do is list some of the other rules that probabilities satisfy. These rules can be derived from the simple assumptions that I’ve outlined above, but since we don’t actually use these rules for anything in this book, I won’t do so here.</p>
<table>
<thead>
<tr class="header">
<th align="left">English</th>
<th align="right">Notation</th>
<th></th>
<th align="left">Formula</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">not <span class="math inline">\(A\)</span></td>
<td align="right"><span class="math inline">\(P(\neg A)\)</span></td>
<td><span class="math inline">\(=\)</span></td>
<td align="left"><span class="math inline">\(1-P(A)\)</span></td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(A\)</span> or <span class="math inline">\(B\)</span></td>
<td align="right"><span class="math inline">\(P(A \cup B)\)</span></td>
<td><span class="math inline">\(=\)</span></td>
<td align="left"><span class="math inline">\(P(A) + P(B) - P(A \cap B)\)</span></td>
</tr>
<tr class="odd">
<td align="left"><span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span></td>
<td align="right"><span class="math inline">\(P(A \cap B)\)</span></td>
<td><span class="math inline">\(=\)</span></td>
<td align="left"><span class="math inline">\(P(A|B) \cdot P(B)\)</span></td>
</tr>
</tbody>
</table>
<p>You don’t really need to know these rules in order to understand the analyses that we’ll talk about later in the book, but they are important if you want to understand probability theory a bit more deeply.</p>
</div>
<div id="probability-distributions" class="section level2">
<h2><span class="header-section-number">4.5</span> Probability distributions</h2>
<p>You just saw your first probability distribution in Figure <a href="week-4-probability-sampling-and-estimation.html#fig:pantsprob">4.9</a>. The concept of a probability distributions is hugely important for understanding inferential statistics. As you might imagine, probability distributions can vary enormously, and there’s a large range of different distributions out there. However, not all probability distributions are equally important. In fact, the vast majority of the content in this book relies on one of three distributions: the binomial distribution, the normal distribution and the <span class="math inline">\(t\)</span> distribution. Given this, what I’ll do over the next few sections is provide a brief introduction to these distributions, paying special attention to the binomial and the normal. I’ll start with the binomial distribution, since it’s the simplest of the three.</p>
<div id="the-binomial-distribution" class="section level3">
<h3><span class="header-section-number">4.5.1</span> The binomial distribution</h3>
<p>The theory of probability originated in the attempt to describe how games of chance work, so it seems fitting that our discussion of the <strong>binomial distribution</strong> should involve a discussion of rolling dice and flipping coins. Let’s imagine a simple “experiment”: in my hot little hand I’m holding 20 identical six-sided dice. On one face of each die there’s a picture of a skull; the other five faces are all blank. If I proceed to roll all 20 dice, what’s the probability that I’ll get exactly 4 skulls? Assuming that the dice are fair, we know that the chance of any one die coming up skulls is 1 in 6; to say this another way, the skull probability for a single die is approximately <span class="math inline">\(.167\)</span>. This is enough information to answer our question, so let’s have a look at how it’s done.</p>
<p>As usual, we have to introduce some names and some notation. We’ll let <span class="math inline">\(N\)</span> denote the number of dice rolls in our experiment; which is often referred to as the <em>size parameter</em> of our binomial distribution. We’ll also use <span class="math inline">\(\theta\)</span> (theta) to refer to the the probability that a single die comes up skulls, a quantity that is usually called the <em>success probability</em> of the binomial. Finally, we’ll use <span class="math inline">\(X\)</span> to refer to the results of our experiment, namely the number of skulls I get when I roll the dice. Since the actual value of <span class="math inline">\(X\)</span> is due to chance, we refer to it as a <em>random variable</em>. In any case, now that we have all this terminology and notation, we can use it to state the problem a little more precisely. The quantity that we want to calculate is the probability that <span class="math inline">\(X = 4\)</span> given that we know that <span class="math inline">\(\theta = .167\)</span> and <span class="math inline">\(N=20\)</span>. The general “form” of the thing I’m interested in calculating could be written as <span class="math display">\[P(X \ | \ \theta, N)\]</span> (say: the probability of <span class="math inline">\(X\)</span> given <span class="math inline">\(\theta\)</span> and <span class="math inline">\(N\)</span>) and we’re interested in the special case where <span class="math inline">\(X=4\)</span>, <span class="math inline">\(\theta = .167\)</span> and <span class="math inline">\(N=20\)</span>. There’s only one more piece of notation I want to refer to before moving on to discuss the solution to the problem. If I want to say that <span class="math inline">\(X\)</span> is generated randomly from a binomial distribution with parameters <span class="math inline">\(\theta\)</span> and <span class="math inline">\(N\)</span>, the notation I would use is as follows: <span class="math display">\[X \sim \mbox{Binomial}(\theta, N)\]</span></p>
<p>Yeah, yeah. I know what you’re thinking: notation, notation, notation. Really, who cares? Very few readers of this book are here for the notation, so I should probably move on and talk about how to use the binomial distribution. To that end, Figure <a href="week-4-probability-sampling-and-estimation.html#fig:4binomial1">4.10</a> plots the binomial probabilities for all possible values of <span class="math inline">\(X\)</span> for our dice rolling experiment, from <span class="math inline">\(X=0\)</span> (no skulls) all the way up to <span class="math inline">\(X=20\)</span> (all skulls). Note that this is basically a bar chart, and is no different to the “pants probability” plot I drew in Figure <a href="week-4-probability-sampling-and-estimation.html#fig:pantsprob">4.9</a>. On the horizontal axis we have all the possible events, and on the vertical axis we can read off the probability of each of those events. So, the probability of rolling 4 skulls out of 20 times is about 0.20 (the actual answer is 0.2022036, as we’ll see in a moment). In other words, you’d expect that to happen about 20% of the times you repeated this experiment.</p>
<div class="figure"><span id="fig:4binomial1"></span>
<img src="figures/probability/binomSkulls20-eps-converted-to.png" alt="The binomial distribution with size parameter of N =20 and an underlying success probability of 1/6. Each vertical bar depicts the probability of one specific outcome (i.e., one possible value of X). Because this is a probability distribution, each of the probabilities must be a number between 0 and 1, and the heights of the bars must sum to 1 as well." width="1164" />
<p class="caption">
Figure 4.10: The binomial distribution with size parameter of N =20 and an underlying success probability of 1/6. Each vertical bar depicts the probability of one specific outcome (i.e., one possible value of X). Because this is a probability distribution, each of the probabilities must be a number between 0 and 1, and the heights of the bars must sum to 1 as well.
</p>
</div>
</div>
<div id="working-with-the-binomial-distribution-in-r" class="section level3">
<h3><span class="header-section-number">4.5.2</span> Working with the binomial distribution in R</h3>
<p>Although some people find it handy to know the formula <a href="https://en.wikipedia.org/wiki/Binomial_distribution#Probability_mass_function">for calculating probabilities from a binomial distribution</a>, most people just want to know how to use the distributions without worrying too much about the maths. To that end, R has a function called <code>dbinom()</code> that calculates binomial probabilities for us.</p>
<p>The main arguments to the function are:</p>
<ul>
<li><code>x</code>: a number, or vector of numbers, specifying the outcomes whose probability you’re trying to calculate.</li>
<li><code>size</code>: a number telling R the size of the experiment.</li>
<li><code>prob</code>: the success probability for any one trial in the experiment.</li>
</ul>
<p>So, in order to calculate the probability of getting skulls, from an experiment of trials, in which the probability of getting a skull on any one trial is … well, the command I would use is simply this:</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="week-4-probability-sampling-and-estimation.html#cb15-1"></a><span class="kw">dbinom</span>( <span class="dt">x =</span> <span class="dv">4</span>, <span class="dt">size =</span> <span class="dv">20</span>, <span class="dt">prob =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">6</span> )</span></code></pre></div>
<pre><code>## [1] 0.2022036</code></pre>
<p>To give you a feel for how the binomial distribution changes when we alter the values of <span class="math inline">\(\theta\)</span> and <span class="math inline">\(N\)</span>, let’s suppose that instead of rolling dice, I’m actually flipping coins. This time around, my experiment involves flipping a fair coin repeatedly, and the outcome that I’m interested in is the number of heads that I observe. In this scenario, the success probability is now <span class="math inline">\(\theta = 1/2\)</span>. Suppose I were to flip the coin <span class="math inline">\(N=20\)</span> times. In this example, I’ve changed the success probability, but kept the size of the experiment the same. What does this do to our binomial distribution?</p>
<div class="figure"><span id="fig:4binomial2"></span>
<img src="figures/probability/Binomial2.png" alt="Two binomial distributions, involving a scenario in which I'm flipping a fair coin, so the underlying success probability is 1/2. In panel (a), we assume I'm flipping the coin N = 20 times. In panel (b) we assume that the coin is flipped N = 100 times." width="507" />
<p class="caption">
Figure 4.11: Two binomial distributions, involving a scenario in which I’m flipping a fair coin, so the underlying success probability is 1/2. In panel (a), we assume I’m flipping the coin N = 20 times. In panel (b) we assume that the coin is flipped N = 100 times.
</p>
</div>
<p>Well, as Figure <a href="week-4-probability-sampling-and-estimation.html#fig:4binomial2">4.11</a>a shows, the main effect of this is to shift the whole distribution, as you’d expect. Okay, what if we flipped a coin <span class="math inline">\(N=100\)</span> times? Well, in that case, we get Figure <a href="week-4-probability-sampling-and-estimation.html#fig:4binomial2">4.11</a>b. The distribution stays roughly in the middle, but there’s a bit more variability in the possible outcomes.</p>
<p>At this point, I should probably explain the name of the <code>dbinom</code> function. Obviously, the “binom” part comes from the fact that we’re working with the binomial distribution, but the “d” prefix is probably a bit of a mystery. In this section I’ll give a partial explanation: specifically, I’ll explain why there is a prefix. As for why it’s a “d” specifically, you’ll have to wait until the next section. What’s going on here is that R actually provides <strong>four</strong> functions in relation to the binomial distribution. These four functions are <code>dbinom</code>, <code>pbinom</code>, <code>rbinom</code> and <code>qbinom</code>, and each one calculates a different quantity of interest. Not only that, R does the same thing for <strong>every</strong> probability distribution that it implements. No matter what distribution you’re talking about, there’s a <code>d</code> function, a <code>p</code> function, <code>r</code> a function and a <code>q</code> function.</p>
<p>Let’s have a look at what all four functions do. Firstly, all four versions of the function require you to specify the <code>size</code> and <code>prob</code> arguments: no matter what you’re trying to get R to calculate, it needs to know what the parameters are. However, they differ in terms of what the other argument is, and what the output is. So let’s look at them one at a time.</p>
<ul>
<li><p>The <code>d</code> form we’ve already seen: you specify a particular outcome <code>x</code>, and the output is the probability of obtaining exactly that outcome. (the “d” is short for <em>density</em>, but ignore that for now).</p></li>
<li><p>The <code>p</code> form calculates the <em>cumulative probability</em>. You specify a particular quantile <code>q</code> , and it tells you the probability of obtaining an outcome <strong>smaller than or equal to</strong> <code>q</code>.</p></li>
</ul>
<div class="marginnote">
<p>Probably you already know what a quantile is (they’re more commonly called percentiles), but if not: the 10th quantile/percentile of a data set is the smallest number <span class="math inline">\(x\)</span> such that 10% of the data is less than <span class="math inline">\(x\)</span>. In fact, we’ve already come across the idea: the median of a data set is its 50th quantile / percentile!</p>
</div>
<ul>
<li><p>The <code>q</code> form calculates the <em>quantiles</em> of the distribution. You specify a probability value <code>p</code>, and it gives you the corresponding quantile/percentile. That is, the value of the variable for which there’s a probability <code>p</code> of obtaining an outcome lower than that value.</p></li>
<li><p>The <code>r</code> form is a <em>random number generator</em>: specifically, it generates <code>n</code> random outcomes from the distribution.</p></li>
</ul>
<p>This is a little abstract, so let’s look at some concrete examples. Again, we’ve already covered <code>dbinom</code> so let’s focus on the other three versions. We’ll start with <code>pbinom</code>, and we’ll go back to the skull-dice example. Again, I’m rolling 20 dice, and each die has a 1 in 6 chance of coming up skulls. Suppose, however, that I want to know the probability of rolling 4 <strong>or fewer</strong> skulls. If I wanted to, I could use the <code>dbinom</code> function to calculate the exact probability of rolling 0 skulls, 1 skull, 2 skulls, 3 skulls and 4 skulls and then add these up, but there’s a faster way. Instead, I can calculate this using the <code>pbinom</code> function. Here’s the command:</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="week-4-probability-sampling-and-estimation.html#cb17-1"></a><span class="kw">pbinom</span>(<span class="dt">q=</span> <span class="dv">4</span>, <span class="dt">size =</span> <span class="dv">20</span>, <span class="dt">prob =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">6</span>)</span></code></pre></div>
<pre><code>## [1] 0.7687492</code></pre>
<p>In other words, there is a 76.9% chance that I will roll 4 or fewer skulls. Or, to put it another way, R is telling us that a value of 4 is actually the 76.9th percentile of this binomial distribution.</p>
<p>Next, let’s consider the <code>qbinom</code> function. Let’s say I want to calculate the 75th percentile of the binomial distribution. If we’re sticking with our skulls example, I would use the following command to do this:</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="week-4-probability-sampling-and-estimation.html#cb19-1"></a><span class="kw">qbinom</span>(<span class="dt">p =</span> <span class="fl">0.75</span>, <span class="dt">size =</span> <span class="dv">20</span>, <span class="dt">prob =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">6</span> )</span></code></pre></div>
<pre><code>## [1] 4</code></pre>
<p>Hm. There’s something odd going on here. Let’s think this through. What the <code>qbinom</code> function appears to be telling us is that the 75th percentile of the binomial distribution is 4, even though we saw from the function that 4 is <strong>actually</strong> the 76.9th percentile. And it’s definitely the <code>pbinom</code> function that is correct. I promise. The weirdness here comes from the fact that our binomial distribution doesn’t really <strong>have</strong> a 75th percentile. Not really. Why not? Well, there’s a 56.7% chance of rolling 3 or fewer skulls (you can type <code>pbinom(3, 20, 1/6)</code> to confirm this if you want), and a 76.9% chance of rolling 4 or fewer skulls. So there’s a sense in which the 75th percentile should lie “in between” 3 and 4 skulls. But that makes no sense at all! You can’t roll 20 dice and get 3.9 of them come up skulls. This issue can be handled in different ways: you could report an in between value (or <strong>interpolated</strong> value, to use the technical name) like 3.9, you could round down (to 3) or you could round up (to 4).</p>
<p>The <code>qbinom</code> function rounds upwards: if you ask for a percentile that doesn’t actually exist (like the 75th in this example), R finds the smallest value for which the the percentile rank is <strong>at least</strong> what you asked for. In this case, since the “true” 75th percentile (whatever that would mean) lies somewhere between 3 and 4 skulls, R rounds up and gives you an answer of 4. This subtlety is tedious, I admit, but thankfully it’s only an issue for discrete distributions like the binomial. The other distributions that I’ll talk about (normal and <span class="math inline">\(t\)</span>) are continuous, and so R can always return an exact quantile whenever you ask for it.</p>
<p>Finally, we have the random number generator. To use the <code>rbinom</code> function, you specify how many times R should “simulate” the experiment using the <code>n</code> argument, and it will generate random outcomes from the binomial distribution. So, for instance, suppose I were to repeat my die rolling experiment 100 times. I could get R to simulate the results of these experiments by using the following command:</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="week-4-probability-sampling-and-estimation.html#cb21-1"></a><span class="kw">rbinom</span>(<span class="dt">n =</span> <span class="dv">100</span>, <span class="dt">size =</span> <span class="dv">20</span>, <span class="dt">prob =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">6</span> )</span></code></pre></div>
<pre><code>##   [1] 3 3 6 3 2 5 2 3 3 2 4 2 2 2 3 6 2 4 6 2 2 3 7 6 2 5 2 1 1 2 6 6 3 1 2 4 4
##  [38] 1 2 2 1 3 5 5 5 2 2 1 3 1 4 3 3 3 3 5 4 4 2 3 2 4 4 4 6 4 3 1 3 2 2 1 4 3
##  [75] 3 4 2 2 2 3 3 1 3 4 5 4 3 1 3 1 6 5 4 4 4 5 1 4 4 7</code></pre>
<blockquote>
<p>Note: Since computers are deterministic machines, they can’t actually produce truly random behaviour. Instead, what they do is take advantage of various mathematical functions that share a lot of similarities with true randomness. What this means is that any random numbers generated on a computer are pseudorandom, and the quality of those numbers depends on the specific method used. By default R uses the “Mersenne twister” method. In any case, you can find out more by typing ?Random, but as usual the R help files are fairly dense.</p>
</blockquote>
<p>As you can see, these numbers are pretty much what you’d expect given the distribution shown in Figure <a href="week-4-probability-sampling-and-estimation.html#fig:4binomial1">4.10</a>. Most of the time I roll somewhere between 1 to 5 skulls. There are a lot of subtleties associated with random number generation using a computer, but for the purposes of this book we don’t need to worry too much about them.</p>
</div>
<div id="the-normal-distribution" class="section level3">
<h3><span class="header-section-number">4.5.3</span> The normal distribution</h3>
<p>While the binomial distribution is conceptually the simplest distribution to understand, it’s not the most important one. That particular honour goes to the <em>normal distribution</em>, which is also referred to as “the bell curve” or a “Gaussian distribution”.</p>
<div class="figure"><span id="fig:4normal"></span>
<img src="figures/probability/standardNormal-eps-converted-to.png" alt="The normal distribution with mean = 0 and standard deviation = 1. The x-axis corresponds to the value of some variable, and the y-axis tells us something about how likely we are to observe that value. However, notice that the y-axis is labelled Probability Density and not Probability. There is a subtle and somewhat frustrating characteristic of continuous distributions that makes the y axis behave a bit oddly: the height of the curve here isn't actually the probability of observing a particular x value. On the other hand, it is true that the heights of the curve tells you which x values are more likely (the higher ones!)." width="1164" />
<p class="caption">
Figure 4.12: The normal distribution with mean = 0 and standard deviation = 1. The x-axis corresponds to the value of some variable, and the y-axis tells us something about how likely we are to observe that value. However, notice that the y-axis is labelled Probability Density and not Probability. There is a subtle and somewhat frustrating characteristic of continuous distributions that makes the y axis behave a bit oddly: the height of the curve here isn’t actually the probability of observing a particular x value. On the other hand, it is true that the heights of the curve tells you which x values are more likely (the higher ones!).
</p>
</div>
<p>A normal distribution is described using two parameters, the mean of the distribution <span class="math inline">\(\mu\)</span> and the standard deviation of the distribution <span class="math inline">\(\sigma\)</span>. The notation that we sometimes use to say that a variable <span class="math inline">\(X\)</span> is normally distributed is as follows: <span class="math display">\[X \sim \mbox{Normal}(\mu,\sigma)\]</span> Of course, that’s just notation. It doesn’t tell us anything interesting about the normal distribution itself. The mathematical formula for the normal distribution is:</p>
<div class="figure"><span id="fig:4normalformula"></span>
<img src="figures/probability/Normal_formula.png" alt="Formula for the normal distribution" width="268" />
<p class="caption">
Figure 4.13: Formula for the normal distribution
</p>
</div>
<p>The formula is important enough that everyone who learns statistics should at least look at it, but since this is an introductory text I don’t want to focus on it to much. Instead, we look at how R can be used to work with normal distributions. The R functions for the normal distribution are <em>dnorm()</em>, <em>pnorm()</em>, <em>qnorm()</em> and <em>rnorm()</em>. However, they behave in pretty much exactly the same way as the corresponding functions for the binomial distribution, so there’s not a lot that you need to know. The only thing that I should point out is that the argument names for the parameters are <em>mean</em> and <em>sd</em>. In pretty much every other respect, there’s nothing else to add.</p>
<p>Instead of focusing on the maths, let’s try to get a sense for what it means for a variable to be normally distributed. To that end, have a look at Figure <a href="week-4-probability-sampling-and-estimation.html#fig:4normal">4.12</a>, which plots a normal distribution with mean <span class="math inline">\(\mu = 0\)</span> and standard deviation <span class="math inline">\(\sigma = 1\)</span>. You can see where the name “bell curve” comes from: it looks a bit like a bell. Notice that, unlike the plots that I drew to illustrate the binomial distribution, the picture of the normal distribution in Figure <a href="week-4-probability-sampling-and-estimation.html#fig:4normal">4.12</a> shows a smooth curve instead of “histogram-like” bars. This isn’t an arbitrary choice: the normal distribution is continuous, whereas the binomial is discrete. For instance, in the die rolling example from the last section, it was possible to get 3 skulls or 4 skulls, but impossible to get 3.9 skulls.</p>
<p>With this in mind, let’s see if we can get an intuition for how the normal distribution works. Firstly, let’s have a look at what happens when we play around with the parameters of the distribution. One parameter we can change is the mean. This will shift the distribution to the right or left. The animation below shows a normal distribution with mean = 0, moving up and down from mean = 0 to mean = 5. Note, when you change the mean the whole shape of the distribution does not change, it just shifts from left to right. In the animation the normal distribution bounces up and down a little, but that’s just a quirk of the animation (plus it looks fun that way).</p>
<div class="figure"><span id="fig:4normalMeanShift"></span>
<img src="figures/gifs/normalMovingMean-1.gif" alt="A normal distribution with a moving mean"  />
<p class="caption">
Figure 4.14: A normal distribution with a moving mean
</p>
</div>
<p>In contrast, if we increase the standard deviation while keeping the mean constant, the peak of the distribution stays in the same place, but the distribution gets wider. The next animation shows what happens when you start with a small standard deviation (sd=0.5), and move to larger and larger standard deviation (up to sd =5). As you can see, the distribution spreads out and becomes wider as the standard deviation increases.</p>
<div class="figure"><span id="fig:4normalSDShift"></span>
<img src="figures/gifs/normalMovingSD-1.gif" alt="A normal distribution with a shifting sd"  />
<p class="caption">
Figure 4.15: A normal distribution with a shifting sd
</p>
</div>
<p>Notice, though, that when we widen the distribution, the height of the peak shrinks. This has to happen: in the same way that the heights of the bars that we used to draw a discrete binomial distribution have to <em>sum</em> to 1, the total <em>area under the curve</em> for the normal distribution must equal 1. Before moving on, I want to point out one important characteristic of the normal distribution. Irrespective of what the actual mean and standard deviation are, approximately 68% of the area falls within 1 standard deviation of the mean (68.3% to be exact). Similarly, approximately 95% of the distribution falls within 2 standard deviations of the mean (95.4% to be exact), and 99.7% of the distribution is within 3 standard deviations. This idea is illustrated in the figures below.</p>
<div class="figure"><span id="fig:sdnorm1a"></span>
<img src="quantrma_files/figure-html/sdnorm1a-1.png" alt="The area under the curve tells you the probability that an observation falls within a particular range. The solid lines plot normal distributions with mean $\mu=0$ and standard deviation $\sigma=1$. The shaded areas illustrate &quot;areas under the curve&quot; for two important cases. Here we can see that there is a 68.3% chance that an observation will fall within one standard deviation of the mean" width="672" />
<p class="caption">
Figure 4.16: The area under the curve tells you the probability that an observation falls within a particular range. The solid lines plot normal distributions with mean <span class="math inline">\(\mu=0\)</span> and standard deviation <span class="math inline">\(\sigma=1\)</span>. The shaded areas illustrate “areas under the curve” for two important cases. Here we can see that there is a 68.3% chance that an observation will fall within one standard deviation of the mean
</p>
</div>
<div class="figure"><span id="fig:sdnorm1b"></span>
<img src="quantrma_files/figure-html/sdnorm1b-1.png" alt="The area under the curve tells you the probability that an observation falls within a particular range. The solid lines plot normal distributions with mean $mu=0$ and standard deviation $sigma=1$. The shaded areas illustrate &quot;areas under the curve&quot; for two important cases. Here we see that there is a 95.4% chance that an observation will fall within two standard deviations of the mean." width="672" />
<p class="caption">
Figure 4.17: The area under the curve tells you the probability that an observation falls within a particular range. The solid lines plot normal distributions with mean <span class="math inline">\(mu=0\)</span> and standard deviation <span class="math inline">\(sigma=1\)</span>. The shaded areas illustrate “areas under the curve” for two important cases. Here we see that there is a 95.4% chance that an observation will fall within two standard deviations of the mean.
</p>
</div>
<div class="figure"><span id="fig:sdnorm2a"></span>
<img src="quantrma_files/figure-html/sdnorm2a-1.png" alt="Two more examples of the &quot;area under the curve idea&quot;. There is a 15.9% chance that an observation is one standard deviation below the mean or smaller" width="672" />
<p class="caption">
Figure 4.18: Two more examples of the “area under the curve idea”. There is a 15.9% chance that an observation is one standard deviation below the mean or smaller
</p>
</div>
<div class="figure"><span id="fig:sdnorm2b"></span>
<img src="quantrma_files/figure-html/sdnorm2b-1.png" alt="There is a 34.1% chance that the observation is greater than one standard deviation below the mean but still below the mean. Notice that if you add these two numbers together you get $15.9 + 34.1 = 50$. For normally distributed data, there is a 50% chance that an observation falls below the mean. And of course that also implies that there is a 50% chance that it falls above the mean." width="672" />
<p class="caption">
Figure 4.19: There is a 34.1% chance that the observation is greater than one standard deviation below the mean but still below the mean. Notice that if you add these two numbers together you get <span class="math inline">\(15.9 + 34.1 = 50\)</span>. For normally distributed data, there is a 50% chance that an observation falls below the mean. And of course that also implies that there is a 50% chance that it falls above the mean.
</p>
</div>
</div>
<div id="probability-density" class="section level3">
<h3><span class="header-section-number">4.5.4</span> Probability density</h3>
<p>There’s something I’ve been trying to hide throughout my discussion of the normal distribution, something that some introductory textbooks omit completely. They might be right to do so: this “thing” that I’m hiding is weird and counterintuitive even by the admittedly distorted standards that apply in statistics. Fortunately, it’s not something that you need to understand at a deep level in order to do basic statistics: rather, it’s something that starts to become important later on when you move beyond the basics. So, if it doesn’t make complete sense, don’t worry: try to make sure that you follow the gist of it.</p>
<p>Throughout my discussion of the normal distribution, there’s been one or two things that don’t quite make sense. Perhaps you noticed that the <span class="math inline">\(y\)</span>-axis in these figures is labelled “Probability Density” rather than density. Maybe you noticed that I used <span class="math inline">\(p(X)\)</span> instead of <span class="math inline">\(P(X)\)</span> when giving the formula for the normal distribution. Maybe you’re wondering why R uses the “d” prefix for functions like <em>dnorm()</em>. And maybe, just maybe, you’ve been playing around with the <em>dnorm()</em> function, and you accidentally typed in a command like this:</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb23-1"><a href="week-4-probability-sampling-and-estimation.html#cb23-1"></a><span class="kw">dnorm</span>( <span class="dt">x =</span> <span class="dv">1</span>, <span class="dt">mean =</span> <span class="dv">1</span>, <span class="dt">sd =</span> <span class="fl">0.1</span> )</span></code></pre></div>
<pre><code>## [1] 3.989423</code></pre>
<p>And if you’ve done the last part, you’re probably very confused. I’ve asked R to calculate the probability that <em>x = 1</em>, for a normally distributed variable with <em>mean = 1</em> and standard deviation <em>sd = 0.1</em>; and it tells me that the probability is 3.99. But, as we discussed earlier, probabilities <em>can’t</em> be larger than 1. So either I’ve made a mistake, or that’s not a probability.</p>
<p>As it turns out, the second answer is correct. What we’ve calculated here isn’t actually a probability: it’s something else. To understand what that something is, you have to spend a little time thinking about what it really <em>means</em> to say that <span class="math inline">\(X\)</span> is a continuous variable. Let’s say we’re talking about the temperature outside. The thermometer tells me it’s 23 degrees, but I know that’s not really true. It’s not <em>exactly</em> 23 degrees. Maybe it’s 23.1 degrees, I think to myself. But I know that that’s not really true either, because it might actually be 23.09 degrees. But, I know that… well, you get the idea. The tricky thing with genuinely continuous quantities is that you never really know exactly what they are.</p>
<p>Now think about what this implies when we talk about probabilities. Suppose that tomorrow’s maximum temperature is sampled from a normal distribution with mean 23 and standard deviation 1. What’s the probability that the temperature will be <em>exactly</em> 23 degrees? The answer is “zero”, or possibly, “a number so close to zero that it might as well be zero”. Why is this?</p>
<p>It’s like trying to throw a dart at an infinitely small dart board: no matter how good your aim, you’ll never hit it. In real life you’ll never get a value of exactly 23. It’ll always be something like 23.1 or 22.99998 or something. In other words, it’s completely meaningless to talk about the probability that the temperature is exactly 23 degrees. However, in everyday language, if I told you that it was 23 degrees outside and it turned out to be 22.9998 degrees, you probably wouldn’t call me a liar. Because in everyday language, “23 degrees” usually means something like “somewhere between 22.5 and 23.5 degrees”. And while it doesn’t feel very meaningful to ask about the probability that the temperature is exactly 23 degrees, it does seem sensible to ask about the probability that the temperature lies between 22.5 and 23.5, or between 20 and 30, or any other range of temperatures.</p>
<p>The point of this discussion is to make clear that, when we’re talking about continuous distributions, it’s not meaningful to talk about the probability of a specific value. However, what we <em>can</em> talk about is the <strong>probability that the value lies within a particular range of values</strong>. To find out the probability associated with a particular range, what you need to do is calculate the “area under the curve”.</p>
<p>Okay, so that explains part of the story. I’ve explained a little bit about how continuous probability distributions should be interpreted (i.e., area under the curve is the key thing), but I haven’t actually explained what the <em>dnorm()</em> function actually calculates. Equivalently, what does the formula for <span class="math inline">\(p(x)\)</span> that I described earlier actually mean? Obviously, <span class="math inline">\(p(x)\)</span> doesn’t describe a probability, but what is it? The name for this quantity <span class="math inline">\(p(x)\)</span> is a <em>probability density</em>, and in terms of the plots we’ve been drawing, it corresponds to the <em>height</em> of the curve. The densities themselves aren’t meaningful in and of themselves: but they’re “rigged” to ensure that the <em>area</em> under the curve is always interpretable as genuine probabilities. To be honest, that’s about as much as you really need to know for now.</p>
</div>
</div>
<div id="other-useful-distributions" class="section level2">
<h2><span class="header-section-number">4.6</span> Other useful distributions</h2>
<p>The normal distribution is the distribution that statistics makes most use of (for reasons to be discussed shortly), and the binomial distribution is a very useful one for lots of purposes. But the world of statistics is filled with probability distributions (like the the <span class="math inline">\(\chi^2\)</span> distribution or the <span class="math inline">\(F\)</span> distribution), some of which we’ll run into in passing. In particular, the <span class="math inline">\(t\)</span> distribution will appear later in this book. I won’t give formulas for the <span class="math inline">\(t\)</span> distribution, or talk about it in too much detail, but I will show you a picture:</p>
<div class="figure"><span id="fig:tdist"></span>
<img src="quantrma_files/figure-html/tdist-1.png" alt="A $t$ distribution with 3 degrees of freedom (solid line). It looks similar to a normal distribution, but it's not quite the same. For comparison purposes, I've plotted a standard normal distribution as the dashed line. Note that the &quot;tails&quot; of the $t$ distribution are &quot;heavier&quot; (i.e., extend further outwards) than the tails of the normal distribution? That's the important difference between the two. " width="672" />
<p class="caption">
Figure 4.20: A <span class="math inline">\(t\)</span> distribution with 3 degrees of freedom (solid line). It looks similar to a normal distribution, but it’s not quite the same. For comparison purposes, I’ve plotted a standard normal distribution as the dashed line. Note that the “tails” of the <span class="math inline">\(t\)</span> distribution are “heavier” (i.e., extend further outwards) than the tails of the normal distribution? That’s the important difference between the two.
</p>
</div>
</div>
<div id="summary-of-probability" class="section level2">
<h2><span class="header-section-number">4.7</span> Summary of Probability</h2>
<p>We’ve talked what probability means, and why statisticians can’t agree on what it means. We talked about the rules that probabilities have to obey. And we introduced the idea of a probability distribution, and spent a good chunk talking about some of the more important probability distributions that statisticians work with. We talked about things like this:</p>
<ul>
<li><p>Probability theory versus statistics</p></li>
<li><p>Frequentist versus Bayesian views of probability</p></li>
<li><p>Basics of probability theory</p></li>
<li><p>Binomial distribution, normal distribution</p></li>
</ul>
<p>As you’d expect, this coverage is by no means exhaustive. Probability theory is a large branch of mathematics in its own right, entirely separate from its application to statistics and data analysis. As such, there are thousands of books written on the subject and universities generally offer multiple classes devoted entirely to probability theory. Even the “simpler” task of documenting standard probability distributions is a big topic.Fortunately for you, very little of this is necessary. You’re unlikely to need to know dozens of statistical distributions when you go out and do real world data analysis, and you definitely won’t need them for this book, but it never hurts to know that there’s other possibilities out there.</p>
<p>Picking up on that last point, there’s a sense in which this whole chapter is something of a digression. Many undergraduate psychology classes on statistics skim over this content very quickly (I know mine did), and even the more advanced classes will often “forget” to revisit the basic foundations of the field. Most academic psychologists would not know the difference between probability and density, and until recently very few would have been aware of the difference between Bayesian and frequentist probability. However, I think it’s important to understand these things before moving onto the applications. For example, there are a lot of rules about what you’re “allowed” to say when doing statistical inference, and many of these can seem arbitrary and weird. However, they start to make sense if you understand that there is this Bayesian/frequentist distinction.</p>
</div>
<div id="samples-populations-and-sampling" class="section level2">
<h2><span class="header-section-number">4.8</span> Samples, populations and sampling</h2>
<p>Remember, the role of descriptive statistics is to concisely summarize what we <strong>do</strong> know. In contrast, the purpose of inferential statistics is to “learn what we do not know from what we do”. What kinds of things would we like to learn about? And how do we learn them? These are the questions that lie at the heart of inferential statistics, and they are traditionally divided into two “big ideas”: estimation and hypothesis testing. The goal in this chapter is to introduce the first of these big ideas, estimation theory, but we’ll talk about sampling theory first because estimation theory doesn’t make sense until you understand sampling. So, this chapter divides into sampling theory, and how to make use of sampling theory to discuss how statisticians think about estimation. We have already done lots of sampling, so you are already familiar with some of the big ideas.</p>
<p><strong>Sampling theory</strong> plays a huge role in specifying the assumptions upon which your statistical inferences rely. And in order to talk about “making inferences” the way statisticians think about it, we need to be a bit more explicit about what it is that we’re drawing inferences <strong>from</strong> (the sample) and what it is that we’re drawing inferences <strong>about</strong> (the population).</p>
<p>In almost every situation of interest, what we have available to us as researchers is a <strong>sample</strong> of data. We might have run experiment with some number of participants; a polling company might have phoned some number of people to ask questions about voting intentions; etc. Regardless: the data set available to us is finite, and incomplete. We can’t possibly get every person in the world to do our experiment; a polling company doesn’t have the time or the money to ring up every voter in the country etc. In our earlier discussion of descriptive statistics, this sample was the only thing we were interested in. Our only goal was to find ways of describing, summarizing and graphing that sample. This is about to change.</p>
<div id="defining-a-population" class="section level3">
<h3><span class="header-section-number">4.8.1</span> Defining a population</h3>
<p>A sample is a concrete thing. You can open up a data file, and there’s the data from your sample. A <strong>population</strong>, on the other hand, is a more abstract idea. It refers to the set of all possible people, or all possible observations, that you want to draw conclusions about, and is generally <strong>much</strong> bigger than the sample. In an ideal world, the researcher would begin the study with a clear idea of what the population of interest is, since the process of designing a study and testing hypotheses about the data that it produces does depend on the population about which you want to make statements. However, that doesn’t always happen in practice: usually the researcher has a fairly vague idea of what the population is and designs the study as best he/she can on that basis.</p>
<p>Sometimes it’s easy to state the population of interest. For instance, in the “polling company” example, the population consisted of all voters enrolled at the a time of the study – millions of people. The sample was a set of 1000 people who all belong to that population. In most situations the situation is much less simple. In a typical a psychological experiment, determining the population of interest is a bit more complicated. Suppose I run an experiment using 100 undergraduate students as my participants. My goal, as a cognitive scientist, is to try to learn something about how the mind works. So, which of the following would count as “the population”:</p>
<ul>
<li><p>All of the undergraduate psychology students at the University of Adelaide?</p></li>
<li><p>Undergraduate psychology students in general, anywhere in the world?</p></li>
<li><p>Australians currently living?</p></li>
<li><p>Australians of similar ages to my sample?</p></li>
<li><p>Anyone currently alive?</p></li>
<li><p>Any human being, past, present or future?</p></li>
<li><p>Any biological organism with a sufficient degree of intelligence operating in a terrestrial environment?</p></li>
<li><p>Any intelligent being?</p></li>
</ul>
<p>Each of these defines a real group of mind-possessing entities, all of which might be of interest to me as a cognitive scientist, and it’s not at all clear which one ought to be the true population of interest.</p>
</div>
<div id="simple-random-samples" class="section level3">
<h3><span class="header-section-number">4.8.2</span> Simple random samples</h3>
<p>Irrespective of how we define the population, the critical point is that the sample is a subset of the population, and our goal is to use our knowledge of the sample to draw inferences about the properties of the population. The relationship between the two depends on the <strong>procedure</strong> by which the sample was selected. This procedure is referred to as a <strong>sampling method</strong>, and it is important to understand why it matters.</p>
<p>To keep things simple, imagine we have a bag containing 10 chips. Each chip has a unique letter printed on it, so we can distinguish between the 10 chips. The chips come in two colors, black and white.</p>
<div class="figure"><span id="fig:srs1"></span>
<img src="figures/estimation/srs1.pdf" alt="Simple random sampling without replacement from a finite population"  />
<p class="caption">
Figure 4.21: Simple random sampling without replacement from a finite population
</p>
</div>
<p>This set of chips is the population of interest, and it is depicted graphically on the left of Figure <a href="week-4-probability-sampling-and-estimation.html#fig:srs1">4.21</a>.</p>
<p>As you can see from looking at the picture, there are 4 black chips and 6 white chips, but of course in real life we wouldn’t know that unless we looked in the bag. Now imagine you run the following “experiment”: you shake up the bag, close your eyes, and pull out 4 chips without putting any of them back into the bag. First out comes the <span class="math inline">\(a\)</span> chip (black), then the <span class="math inline">\(c\)</span> chip (white), then <span class="math inline">\(j\)</span> (white) and then finally <span class="math inline">\(b\)</span> (black). If you wanted, you could then put all the chips back in the bag and repeat the experiment, as depicted on the right hand side of Figure<a href="week-4-probability-sampling-and-estimation.html#fig:srs1">4.21</a>. Each time you get different results, but the procedure is identical in each case. The fact that the same procedure can lead to different results each time, we refer to it as a <strong>random</strong> process. However, because we shook the bag before pulling any chips out, it seems reasonable to think that every chip has the same chance of being selected. A procedure in which every member of the population has the same chance of being selected is called a <strong>simple random sample</strong>. The fact that we did <strong>not</strong> put the chips back in the bag after pulling them out means that you can’t observe the same thing twice, and in such cases the observations are said to have been sampled <strong>without replacement</strong>.</p>
<p>To help make sure you understand the importance of the sampling procedure, consider an alternative way in which the experiment could have been run. Suppose that my 5-year old son had opened the bag, and decided to pull out four black chips without putting any of them back in the bag. This <strong>biased</strong> sampling scheme is depicted in Figure <a href="week-4-probability-sampling-and-estimation.html#fig:brs">4.22</a>.</p>
<div class="figure"><span id="fig:brs"></span>
<img src="figures/estimation/brs.pdf" alt="Biased sampling without replacement from a finite population"  />
<p class="caption">
Figure 4.22: Biased sampling without replacement from a finite population
</p>
</div>
<p>Now consider the evidentiary value of seeing 4 black chips and 0 white chips. Clearly, it depends on the sampling scheme, does it not? If you know that the sampling scheme is biased to select only black chips, then a sample that consists of only black chips doesn’t tell you very much about the population! For this reason, statisticians really like it when a data set can be considered a simple random sample, because it makes the data analysis <strong>much</strong> easier.</p>
<p>A third procedure is worth mentioning. This time around we close our eyes, shake the bag, and pull out a chip. This time, however, we record the observation and then put the chip back in the bag. Again we close our eyes, shake the bag, and pull out a chip. We then repeat this procedure until we have 4 chips. Data sets generated in this way are still simple random samples, but because we put the chips back in the bag immediately after drawing them it is referred to as a sample <strong>with replacement</strong>. The difference between this situation and the first one is that it is possible to observe the same population member multiple times, as illustrated in Figure <a href="week-4-probability-sampling-and-estimation.html#fig:srs2">4.23</a>.</p>
<div class="figure"><span id="fig:srs2"></span>
<img src="figures/estimation/srs2.pdf" alt="Simple random sampling with replacement from a finite population"  />
<p class="caption">
Figure 4.23: Simple random sampling with replacement from a finite population
</p>
</div>
<p>Most psychology experiments tend to be sampling without replacement, because the same person is not allowed to participate in the experiment twice. However, most statistical theory is based on the assumption that the data arise from a simple random sample <strong>with</strong> replacement. In real life, this very rarely matters. If the population of interest is large (e.g., has more than 10 entities!) the difference between sampling with- and without- replacement is too small to be concerned with. The difference between simple random samples and biased samples, on the other hand, is not such an easy thing to dismiss.</p>
</div>
<div id="most-samples-are-not-simple-random-samples" class="section level3">
<h3><span class="header-section-number">4.8.3</span> Most samples are not simple random samples</h3>
<p>As you can see from looking at the list of possible populations that I showed above, it is almost impossible to obtain a simple random sample from most populations of interest. When I run experiments, I’d consider it a minor miracle if my participants turned out to be a random sampling of the undergraduate psychology students at Adelaide university, even though this is by far the narrowest population that I might want to generalize to. A thorough discussion of other types of sampling schemes is beyond the scope of this book, but to give you a sense of what’s out there I’ll list a few of the more important ones:</p>
<ul>
<li><p><strong>Stratified sampling</strong>. Suppose your population is (or can be) divided into several different sub-populations, or <strong>strata</strong>. Perhaps you’re running a study at several different sites, for example. Instead of trying to sample randomly from the population as a whole, you instead try to collect a separate random sample from each of the strata. Stratified sampling is sometimes easier to do than simple random sampling, especially when the population is already divided into the distinct strata. It can also be more efficient that simple random sampling, especially when some of the sub-populations are rare. For instance, when studying schizophrenia it would be much better to divide the population into two strata (schizophrenic and not-schizophrenic), and then sample an equal number of people from each group. If you selected people randomly, you would get so few schizophrenic people in the sample that your study would be useless. This specific kind of of stratified sampling is referred to as <strong>oversampling</strong> because it makes a deliberate attempt to over-represent rare groups.</p></li>
<li><p><strong>Snowball sampling</strong> is a technique that is especially useful when sampling from a “hidden” or hard to access population, and is especially common in social sciences. For instance, suppose the researchers want to conduct an opinion poll among transgender people. The research team might only have contact details for a few trans folks, so the survey starts by asking them to participate (stage 1). At the end of the survey, the participants are asked to provide contact details for other people who might want to participate. In stage 2, those new contacts are surveyed. The process continues until the researchers have sufficient data. The big advantage to snowball sampling is that it gets you data in situations that might otherwise be impossible to get any. On the statistical side, the main disadvantage is that the sample is highly non-random, and non-random in ways that are difficult to address. On the real life side, the disadvantage is that the procedure can be unethical if not handled well, because hidden populations are often hidden for a reason. I chose transgender people as an example here to highlight this: if you weren’t careful you might end up outing people who don’t want to be outed (very, very bad form), and even if you don’t make that mistake it can still be intrusive to use people’s social networks to study them. It’s certainly very hard to get people’s informed consent <strong>before</strong> contacting them, yet in many cases the simple act of contacting them and saying “hey we want to study you” can be hurtful. Social networks are complex things, and just because you can use them to get data doesn’t always mean you should.</p></li>
<li><p><strong>Convenience sampling</strong> is more or less what it sounds like. The samples are chosen in a way that is convenient to the researcher, and not selected at random from the population of interest. Snowball sampling is one type of convenience sampling, but there are many others. A common example in psychology are studies that rely on undergraduate psychology students. These samples are generally non-random in two respects: firstly, reliance on undergraduate psychology students automatically means that your data are restricted to a single sub-population. Secondly, the students usually get to pick which studies they participate in, so the sample is a self selected subset of psychology students not a randomly selected subset. In real life, most studies are convenience samples of one form or another. This is sometimes a severe limitation, but not always.</p></li>
</ul>
</div>
<div id="how-much-does-it-matter-if-you-dont-have-a-simple-random-sample" class="section level3">
<h3><span class="header-section-number">4.8.4</span> How much does it matter if you don’t have a simple random sample?</h3>
<p>Okay, so real world data collection tends not to involve nice simple random samples. Does that matter? A little thought should make it clear to you that it <strong>can</strong> matter if your data are not a simple random sample: just think about the difference between Figures <a href="week-4-probability-sampling-and-estimation.html#fig:srs1">4.21</a> and <a href="week-4-probability-sampling-and-estimation.html#fig:brs">4.22</a>. However, it’s not quite as bad as it sounds. Some types of biased samples are entirely unproblematic. For instance, when using a stratified sampling technique you actually <strong>know</strong> what the bias is because you created it deliberately, often to <strong>increase</strong> the effectiveness of your study, and there are statistical techniques that you can use to adjust for the biases you’ve introduced (not covered in this book!). So in those situations it’s not a problem.</p>
<p>More generally though, it’s important to remember that random sampling is a means to an end, not the end in itself. Let’s assume you’ve relied on a convenience sample, and as such you can assume it’s biased. A bias in your sampling method is only a problem if it causes you to draw the wrong conclusions. When viewed from that perspective, I’d argue that we don’t need the sample to be randomly generated in <strong>every</strong> respect: we only need it to be random with respect to the psychologically-relevant phenomenon of interest. Suppose I’m doing a study looking at working memory capacity. In study 1, I actually have the ability to sample randomly from all human beings currently alive, with one exception: I can only sample people born on a Monday. In study 2, I am able to sample randomly from the Australian population. I want to generalize my results to the population of all living humans. Which study is better? The answer, obviously, is study 1. Why? Because we have no reason to think that being “born on a Monday” has any interesting relationship to working memory capacity. In contrast, I can think of several reasons why “being Australian” might matter. Australia is a wealthy, industrialized country with a very well-developed education system. People growing up in that system will have had life experiences much more similar to the experiences of the people who designed the tests for working memory capacity. This shared experience might easily translate into similar beliefs about how to “take a test”, a shared assumption about how psychological experimentation works, and so on. These things might actually matter. For instance, “test taking” style might have taught the Australian participants how to direct their attention exclusively on fairly abstract test materials relative to people that haven’t grown up in a similar environment; leading to a misleading picture of what working memory capacity is.</p>
<p>There are two points hidden in this discussion. Firstly, when designing your own studies, it’s important to think about what population you care about, and try hard to sample in a way that is appropriate to that population. In practice, you’re usually forced to put up with a “sample of convenience” (e.g., psychology lecturers sample psychology students because that’s the least expensive way to collect data, and our coffers aren’t exactly overflowing with gold), but if so you should at least spend some time thinking about what the dangers of this practice might be.</p>
<p>Secondly, if you’re going to criticize someone else’s study because they’ve used a sample of convenience rather than laboriously sampling randomly from the entire human population, at least have the courtesy to offer a specific theory as to <strong>how</strong> this might have distorted the results. Remember, everyone in science is aware of this issue, and does what they can to alleviate it. Merely pointing out that “the study only included people from group BLAH” is entirely unhelpful, and borders on being insulting to the researchers, who are aware of the issue. They just don’t happen to be in possession of the infinite supply of time and money required to construct the perfect sample. In short, if you want to offer a responsible critique of the sampling process, then be <strong>helpful</strong>. Rehashing the blindingly obvious truisms that I’ve been rambling on about in this section isn’t helpful.</p>
</div>
<div id="population-parameters-and-sample-statistics" class="section level3">
<h3><span class="header-section-number">4.8.5</span> Population parameters and sample statistics</h3>
<p>Okay. Setting aside the thorny methodological issues associated with obtaining a random sample, let’s consider a slightly different issue. Up to this point we have been talking about populations the way a scientist might. To a psychologist, a population might be a group of people. To an ecologist, a population might be a group of bears. In most cases the populations that scientists care about are concrete things that actually exist in the real world.</p>
<p>Statisticians, however, are a funny lot. On the one hand, they <strong>are</strong> interested in real world data and real science in the same way that scientists are. On the other hand, they also operate in the realm of pure abstraction in the way that mathematicians do. As a consequence, statistical theory tends to be a bit abstract in how a population is defined. In much the same way that psychological researchers operationalize our abstract theoretical ideas in terms of concrete measurements, statisticians operationalize the concept of a “population” in terms of mathematical objects that they know how to work with. You’ve already come across these objects they’re called probability distributions (remember, the place where data comes from).</p>
<p>The idea is quite simple. Let’s say we’re talking about IQ scores. To a psychologist, the population of interest is a group of actual humans who have IQ scores. A statistician “simplifies” this by operationally defining the population as the probability distribution depicted in Figure <a href="week-4-probability-sampling-and-estimation.html#fig:IQdist">4.24</a>a.</p>
<p>.</p>
<div class="figure"><span id="fig:IQdist"></span>
<img src="figures/navIQ.png" alt="The population distribution of IQ scores (panel a) and two samples drawn randomly from it. In panel b we have a sample of 100 observations, and panel c we have a sample of 10,000 observations." width="753" />
<p class="caption">
Figure 4.24: The population distribution of IQ scores (panel a) and two samples drawn randomly from it. In panel b we have a sample of 100 observations, and panel c we have a sample of 10,000 observations.
</p>
</div>
<p>IQ tests are designed so that the average IQ is 100, the standard deviation of IQ scores is 15, and the distribution of IQ scores is normal. These values are referred to as the <strong>population parameters</strong> because they are characteristics of the entire population. That is, we say that the population mean <span class="math inline">\(\mu\)</span> is 100, and the population standard deviation <span class="math inline">\(\sigma\)</span> is 15.</p>
<p>Now suppose we collect some data. We select 100 people at random and administer an IQ test, giving a simple random sample from the population. The sample would consist of a collection of numbers like this:</p>
<p><code>106 101 98 80 74 ... 107 72 100</code></p>
<p>Each of these IQ scores is sampled from a normal distribution with mean 100 and standard deviation 15. So if I plot a histogram of the sample, I get something like the one shown in Figure <a href="week-4-probability-sampling-and-estimation.html#fig:IQdist">4.24</a>b. As you can see, the histogram is <strong>roughly</strong> the right shape, but it’s a very crude approximation to the true population distribution shown in Figure <a href="week-4-probability-sampling-and-estimation.html#fig:IQdist">4.24</a>a. The mean of the sample is fairly close to the population mean 100 but not identical. In this case, it turns out that the people in the sample have a mean IQ of 98.5, and the standard deviation of their IQ scores is 15.9. These <strong>sample statistics</strong> are properties of the data set, and although they are fairly similar to the true population values, they are not the same. <strong>In general, sample statistics are the things you can calculate from your data set, and the population parameters are the things you want to learn about.</strong> Later on in this chapter we’ll talk about how you can estimate population parameters using your sample statistics and how to work out how confident you are in your estimates but before we get to that there’s a few more ideas in sampling theory that you need to know about.</p>
</div>
</div>
<div id="the-law-of-large-numbers" class="section level2">
<h2><span class="header-section-number">4.9</span> The law of large numbers</h2>
<p>We just looked at the results of one fictitious IQ experiment with a sample size of <span class="math inline">\(N=100\)</span>. The results were somewhat encouraging: the true population mean is 100, and the sample mean of 98.5 is a pretty reasonable approximation to it. In many scientific studies that level of precision is perfectly acceptable, but in other situations you need to be a lot more precise. If we want our sample statistics to be much closer to the population parameters, what can we do about it?</p>
<p>The obvious answer is to collect more data. Suppose that we ran a much larger experiment, this time measuring the IQ’s of 10,000 people. We can simulate the results of this experiment using R, using the <strong>rnorm()</strong> function, which generates random numbers sampled from a normal distribution. For an experiment with a sample size of <strong>n = 10000</strong>, and a population with <strong>mean = 100</strong> and <strong>sd = 15</strong>, R produces our fake IQ data using these commands:</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb25-1"><a href="week-4-probability-sampling-and-estimation.html#cb25-1"></a>IQ &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dt">n=</span><span class="dv">10000</span>, <span class="dt">mean=</span><span class="dv">100</span>, <span class="dt">sd=</span><span class="dv">15</span>) <span class="co">#generate IQ scores</span></span>
<span id="cb25-2"><a href="week-4-probability-sampling-and-estimation.html#cb25-2"></a>IQ &lt;-<span class="st"> </span><span class="kw">round</span>(IQ) <span class="co"># make round numbers</span></span></code></pre></div>
<p>Cool, we just generated 10,000 fake IQ scores. Where did they go? Well, they went into the variable IQ on my computer. You can do the same on your computer too by copying the above code. 10,000 numbers is too many numbers to look at. We can look at the first 100 like this:</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb26-1"><a href="week-4-probability-sampling-and-estimation.html#cb26-1"></a><span class="kw">print</span>(IQ[<span class="dv">1</span><span class="op">:</span><span class="dv">100</span>])</span></code></pre></div>
<pre><code>##   [1]  87 120  80  75  91 112  70 101 110  93  88  95 109 116  88 113 132 101
##  [19] 124  90 108 102  76  93 100 128  90  99 119  96 112  99  85 116  96  93
##  [37] 114  96  85  84 100 112  83 108  81  97 104 101  95  74  78 107  87  98
##  [55]  88  97 109 117 105  93 101 111 118  87 109 120 102 125 108 104 100  92
##  [73] 117  99 101 117 101  84  90 125 106 103  91 111 108 115 102 121  86  80
##  [91]  74 112 106  95 108 100  90 109  71 103</code></pre>
<p>We can compute the mean IQ using the command <strong>mean(IQ)</strong> and the standard deviation using the command <strong>sd(IQ)</strong>, and draw a histogram using <strong>hist()</strong>. The histogram of this much larger sample is shown in Figure <a href="week-4-probability-sampling-and-estimation.html#fig:IQdist">4.24</a>c. Even a moment’s inspections makes clear that the larger sample is a much better approximation to the true population distribution than the smaller one. This is reflected in the sample statistics: the mean IQ for the larger sample turns out to be 99.9, and the standard deviation is 15.1. These values are now very close to the true population.</p>
<p>I feel a bit silly saying this, but the thing I want you to take away from this is that large samples generally give you better information. I feel silly saying it because it’s so bloody obvious that it shouldn’t need to be said. In fact, it’s such an obvious point that when Jacob Bernoulli – one of the founders of probability theory – formalized this idea back in 1713, he was kind of a jerk about it. Here’s how he described the fact that we all share this intuition:</p>
<blockquote>
<p><strong>For even the most stupid of men, by some instinct of nature, by himself and without any instruction (which is a remarkable thing), is convinced that the more observations have been made, the less danger there is of wandering from one’s goal</strong> (see Stigler, 1986, p65).</p>
</blockquote>
<p>Okay, so the passage comes across as a bit condescending (not to mention sexist), but his main point is correct: it really does feel obvious that more data will give you better answers. The question is, why is this so? Not surprisingly, this intuition that we all share turns out to be correct, and statisticians refer to it as the <strong>law of large numbers</strong>. The law of large numbers is a mathematical law that applies to many different sample statistics, but the simplest way to think about it is as a law about averages. The sample mean is the most obvious example of a statistic that relies on averaging (because that’s what the mean is… an average), so let’s look at that. <strong>When applied to the sample mean, what the law of large numbers states is that as the sample gets larger, the sample mean tends to get closer to the true population mean.</strong> Or, to say it a little bit more precisely, as the sample size “approaches” infinity (written as <span class="math inline">\(N \rightarrow \infty\)</span>) the sample mean approaches the population mean (<span class="math inline">\(\bar{X} \rightarrow \mu\)</span>).</p>
<p>I don’t intend to subject you to a proof that the law of large numbers is true, but it’s one of the most important tools for statistical theory. The law of large numbers is the thing we can use to justify our belief that collecting more and more data will eventually lead us to the truth. For any particular data set, the sample statistics that we calculate from it will be wrong, but the law of large numbers tells us that if we keep collecting more data those sample statistics will tend to get closer and closer to the true population parameters.</p>
</div>
<div id="sampling-distributions-and-the-central-limit-theorem" class="section level2">
<h2><span class="header-section-number">4.10</span> Sampling distributions and the central limit theorem</h2>
<p>The law of large numbers is a very powerful tool, but it’s not going to be good enough to answer all our questions. Among other things, all it gives us is a “long run guarantee”. In the long run, if we were somehow able to collect an infinite amount of data, then the law of large numbers guarantees that our sample statistics will be correct. But as John Maynard Keynes famously argued in economics, a long run guarantee is of little use in real life:</p>
<blockquote>
<p><strong>[The] long run is a misleading guide to current affairs. In the long run we are all dead. Economists set themselves too easy, too useless a task, if in tempestuous seasons they can only tell us, that when the storm is long past, the ocean is flat again.</strong> <span class="citation">Keynes (<a href="#ref-keynes_tract_1923" role="doc-biblioref">1923</a>, 80)</span></p>
</blockquote>
<p>As in economics, so too in psychology and statistics. It is not enough to know that we will <strong>eventually</strong> arrive at the right answer when calculating the sample mean. Knowing that an infinitely large data set will tell me the exact value of the population mean is cold comfort when my <strong>actual</strong> data set has a sample size of <span class="math inline">\(N=100\)</span>. In real life, then, we must know something about the behavior of the sample mean when it is calculated from a more modest data set!</p>
<div id="sampling-distribution-of-the-sample-means" class="section level3">
<h3><span class="header-section-number">4.10.1</span> Sampling distribution of the sample means</h3>
<p>“Oh no, what is the sample distribution of the sample means? Is that even allowed in English?”. Yes, unfortunately, this is allowed. The <strong>sampling distribution of the sample means</strong> is the next most important thing you will need to understand. IT IS SO IMPORTANT THAT IT IS NECESSARY TO USE ALL CAPS. It is only confusing at first because it’s long and uses sampling and sample in the same phrase.</p>
<p>Don’t worry, we’ve been prepping you for this. You know what a distribution is right? It’s where numbers comes from. It makes some numbers occur more or less frequently, or the same as other numbers. You know what a sample is right? It’s the numbers we take from a distribution. So, what could the sampling distribution of the sample means refer to?</p>
<p>First, what do you think the sample means refers to? Well, if you took a sample of numbers, you would have a bunch of numbers…then, you could compute the mean of those numbers. The sample mean is the mean of the numbers in the sample. That is all. So, what is this distribution you speak of? Well, what if you took a bunch of samples, put one here, put one there, put some other ones other places. You have a lot of different samples of numbers. You could compute the mean for each them. Then you would have a bunch of means. What do those means look like? Well, if you put them in a histogram, you could find out. If you did that, you would be looking at (roughly) a distribution, AKA <strong>the sampling distribution of the sample means</strong>.</p>
<p>“I’m following along sort of, why would I want to do this instead of watching Netflix…”. Because, the sampling distribution of the sample means gives you another window into chance. A very useful one that you can control, just like your remote control, by pressing the right design buttons.</p>
</div>
<div id="seeing-the-pieces" class="section level3">
<h3><span class="header-section-number">4.10.2</span> Seeing the pieces</h3>
<p>To make a sampling distribution of the sample means, we just need the following:</p>
<ol style="list-style-type: decimal">
<li>A distribution to take numbers from</li>
<li>A bunch of different samples from the distribution</li>
<li>The means of each of the samples</li>
<li>Get all of the sample means, and plot them in a histogram</li>
</ol>
<hr />
<p>Question for yourself: What do you think the sampling distribution of the sample means will look like? Will it tend to look the shape of the distribution that the samples came from? Or not? Good question, think about it.</p>
<hr />
<p>Let’s do those four things. We will sample numbers from the uniform distribution, it looks like this if we are sampling from the set of integers from 1 to 10:</p>
<div class="figure"><span id="fig:4Unif"></span>
<img src="quantrma_files/figure-html/4Unif-1.png" alt="A uniform distribution illustrating the probabilites of sampling the numbers 1 to 10. In a uniform distribution, all numbers have an equal probability of being sampled, so the line is flat indicating all numbers have the same probability" width="672" />
<p class="caption">
Figure 4.25: A uniform distribution illustrating the probabilites of sampling the numbers 1 to 10. In a uniform distribution, all numbers have an equal probability of being sampled, so the line is flat indicating all numbers have the same probability
</p>
</div>
<p>OK, now let’s take a bunch of samples from that distribution. We will set our sample-size to 20. It’s easier to see how the sample mean behaves in a movie. Each histogram shows a new sample. The red line shows where the mean of the sample is. The samples are all very different from each other, but the red line doesn’t move around very much, it always stays near the middle. However, the red line does move around a little bit, and this variance is what we call the sampling distribution of the sample mean.</p>
<div class="figure"><span id="fig:4sample20unif"></span>
<img src="figures/gifs/sampleHistUnif-1.gif" alt="Animiation showing histograms for different samples of size 20 from the uniform distribution. The red line shows the mean of each sample"  />
<p class="caption">
Figure 4.26: Animiation showing histograms for different samples of size 20 from the uniform distribution. The red line shows the mean of each sample
</p>
</div>
<p>OK, what have we got here? We have an animiation of 10 different samples. Each sample has 20 observations and these are summarized in each of histograms that show up in the animiation. Each histogram has a red line. The red line shows you where the mean of each sample is located. So, we have found the sample means for the 10 different samples from a uniform distribution.</p>
<p>First question. Are the sample means all the same? The answer is no. They are all kind of similar to each other though, they are all around five plus or minus a few numbers. This is interesting. Although all of our samples look pretty different from one another, the means of our samples look more similar than different.</p>
<p>Second question. What should we do with the means of our samples? Well, how about we collect them them all, and then plot a histogram of them. This would allow us to see what the distribution of the sample means looks like. The next histogram is just this. Except, rather than taking 10 samples, we will take 10,000 samples. For each of them we will compute the means. So, we will have 10,000 means. This is the histogram of the sample means:</p>
<div class="figure"><span id="fig:4unifmany"></span>
<img src="quantrma_files/figure-html/4unifmany-1.png" alt="A histogram showing the sample means for 10,000 samples, each size 20, from the uniform distribution of numbers from 1 to 10. The expected mean is 5.5, and the histogram is centered on 5.5. The mean of each sample is not always 5.5 because of sampling error or chance" width="672" />
<p class="caption">
Figure 4.27: A histogram showing the sample means for 10,000 samples, each size 20, from the uniform distribution of numbers from 1 to 10. The expected mean is 5.5, and the histogram is centered on 5.5. The mean of each sample is not always 5.5 because of sampling error or chance
</p>
</div>
<p>“Wait what? This doesn’t look right. I thought we were taking samples from a uniform distribution. Uniform distributions are flat. THIS DOES NOT LOOK LIKE A FLAT DISTRIBTUION, WHAT IS GOING ON, AAAAAGGGHH.”. We feel your pain.</p>
<p>Remember, we are looking at the distribution of sample means. It is indeed true that the distribution of sample means does not look the same as the distribution we took the samples from. Our distribution of sample means goes up and down. In fact, this will almost always be the case for distributions of sample means. This fact is called the <strong>central limit theorem</strong>, which we talk about later.</p>
<p>For now, let’s talk about about what’s happening. Remember, we have been sampling numbers between the range 1 to 10. We are supposed to get each number with roughly equal frequency, because we are sampling from a uniform distribution. So, let’s say we took a sample of 10 numbers, and happened to get one of each from 1 to 10.</p>
<p><code>1 2 3 4 5 6 7 8 9 10</code></p>
<p>What is the mean of those numbers? Well, its 1+2+3+4+5+6+7+8+9+10 = 55 / 10 = 5.5. Imagine if we took a bigger sample, say of 20 numbers, and again we got exactly 2 of each number. What would the mean be? It would be (1+2+3+4+5+6+7+8+9+10)*2 = 110 / 20 = 5.5. Still 5.5. You can see here, that the mean value of our uniform distribution is 5.5. Now that we know this, we might expect that most of our samples will have a mean near this number. We already know that every sample won’t be perfect, and it won’t have exactly an equal amount of every number. So, we will expect the mean of our samples to vary a little bit. The histogram that we made shows the variation. Not surprisingly, the numbers vary around the value 5.5.</p>
</div>
<div id="sampling-distributions-exist-for-any-sample-statistic" class="section level3">
<h3><span class="header-section-number">4.10.3</span> Sampling distributions exist for any sample statistic!</h3>
<p>One thing to keep in mind when thinking about sampling distributions is that <strong>any</strong> sample statistic you might care to calculate has a sampling distribution. For example, suppose that each time you sampled some numbers from an experiment you wrote down the largest number in the experiment. Doing this over and over again would give you a very different sampling distribution, namely the <strong>sampling distribution of the maximum</strong>. You could calculate the smallest number, or the mode, or the median, of the variance, or the standard deviation, or anything else from your sample. Then, you could repeat many times, and produce the sampling distribution of those statistics. Neat!</p>
<p>Just for fun here are some different sampling distributions for different statistics. We will take a normal distribution with mean = 100, and standard deviation =20. Then, we’ll take lots of samples with n = 50 (50 observations per sample). We’ll save all of the sample statistics, then plot their histograms. Let’s do it:</p>
<div class="figure"><span id="fig:4samplestats"></span>
<img src="quantrma_files/figure-html/4samplestats-1.png" alt="Each panel shows a histogram of a different sampling statistic" width="672" />
<p class="caption">
Figure 4.28: Each panel shows a histogram of a different sampling statistic
</p>
</div>
<p>We just computed 4 different sampling distributions, for the mean, standard deviation, maximum value, and the median. If you just look quickly at these histograms you might think they all basically look the same. Hold up now. It’s very important to look at the x-axes. They are different. For example, the sample mean goes from about 90 to 110, whereas the standard deviation goes from 15 to 25.</p>
<p>These sampling distributions are super important, and worth thinking about. What should you think about? Well, here’s a clue. These distributions are telling you what to expect from your sample. Critically, they are telling you what you should expect from a sample, when you take one from the specific distribution that we used (normal distribution with mean =100 and SD = 20). What have we learned. We’ve learned a tonne. We’ve learned that we can expect our sample to have a mean somewhere between 90 and 108ish. Notice, the sample means are never more extreme. We’ve learned that our sample will usually have some variance, and that the the standard deviation will be somewhere between 15 and 25 (never much more extreme than that). We can see that sometime we get some big numbers, say between 120 and 180, but not much bigger than that. And, we can see that the median is pretty similar to the mean. If you ever took a sample of 50 numbers, and your descriptive statistics were inside these windows, then perhaps they came from this kind of normal distribution. If your sample statistics are very different, then your sample probably did not come this distribution. By using simulation, we can find out what samples look like when they come from distributions, and we can use this information to make inferences about whether our sample came from particular distributions.</p>
</div>
</div>
<div id="the-central-limit-theorem" class="section level2">
<h2><span class="header-section-number">4.11</span> The central limit theorem</h2>
<p>OK, so now you’ve seen lots of sampling distributions, and you know what the sampling distribution of the mean is. Here, we’ll focus on <strong>how the sampling distribution of the mean changes as a function of sample size.</strong></p>
<p>Intuitively, you already know part of the answer: if you only have a few observations, the sample mean is likely to be quite inaccurate (you’ve already seen it bounce around): if you replicate a small experiment and recalculate the mean you’ll get a very different answer. In other words, the sampling distribution is quite wide. If you replicate a large experiment and recalculate the sample mean you’ll probably get the same answer you got last time, so the sampling distribution will be very narrow.</p>
<p>Let’s give ourselves a nice movie to see everything in action. We’re going to sample numbers from a normal distribution. You will see four panels, each panel represents a different sample size (n), including sample-sizes of 10, 50, 100, and 1000. The red line shows the shape of the normal distribution. The grey bars show a histogram of each of the samples that we take. The red line shows the mean of an individual sample (the middle of the grey bars). As you can see, the red line moves around a lot, especially when the sample size is small (10).</p>
<p>The new bits are the blue bars and the blue lines. The blue bars represent the sampling distribution of the sample mean. For example, in the panel for sample-size 10, we see a bunch of blue bars. This is a histogram of 10 sample means, taken from 10 samples of size 10. In the 50 panel, we see a histogram of 50 sample means, taken from 50 samples of size 50, and so on. The blue line in each panel is the mean of the sample means (“aaagh, it’s a mean of means”, yes it is).</p>
<div class="figure"><span id="fig:4samplingmean"></span>
<img src="figures/gifs/sampleDistNormal-1.gif" alt="Animation of samples (grey histogram shows frequency counts of data in each sample), and the sampling distribution of the mean (histogram of the sampling means for many samples). Each sample is taken from the normal distribution shown in red. The moving red line is the mean of an individual sample. The blue line is the mean of the blue histogram, which represents the sampling distribution of the mean for many samples"  />
<p class="caption">
Figure 4.29: Animation of samples (grey histogram shows frequency counts of data in each sample), and the sampling distribution of the mean (histogram of the sampling means for many samples). Each sample is taken from the normal distribution shown in red. The moving red line is the mean of an individual sample. The blue line is the mean of the blue histogram, which represents the sampling distribution of the mean for many samples
</p>
</div>
<p>What should you notice? Notice that the range of the blue bars shrinks as sample size increases. The sampling distribution of the mean is quite wide when the sample-size is 10, it narrows as sample-size increases to 50 and 100, and it’s just one bar, right in the middle when sample-size goes to 1000. What we are seeing is that the mean of the sampling distribution approaches the mean of the population as sample-size increases.</p>
<p>So, the sampling distribution of the mean is another distribution, and it has some variance. It varies more when sample-size is small, and varies less when sample-size is large. We can quantify this effect by calculating the standard deviation of the sampling distribution, which is referred to as the <strong>standard error</strong>. The standard error of a statistic is often denoted SE, and since we’re usually interested in the standard error of the sample <strong>mean</strong>, we often use the acronym SEM. As you can see just by looking at the movie, as the sample size <span class="math inline">\(N\)</span> increases, the SEM decreases.</p>
<p>Okay, so that’s one part of the story. However, there’s something we’ve been glossing over a little bit. We’ve seen it already, but it’s worth looking at it one more time. Here’s the thing: <strong>no matter what shape your population distribution is, as <span class="math inline">\(N\)</span> increases the sampling distribution of the mean starts to look more like a normal distribution</strong>. This is the central limit theorem.</p>
<p>To see the central limit theorem in action, we are going to look at some histograms of sample means different kinds of distributions. It is very important to recognize that you are looking at distributions of sample means, not distributions of individual samples! Here we go, starting with sampling from a normal distribution. The red line is the distribution, the blue bars are the histogram for the sample means. They both look normal!</p>
<div class="figure"><span id="fig:4sampledistmeannorm"></span>
<img src="quantrma_files/figure-html/4sampledistmeannorm-1.png" alt="Comparison of two normal distributions, and histograms for the sampling distribution of the mean for different samples-sizes. The range  of sampling distribution of the mean shrinks as sample-size increases" width="672" />
<p class="caption">
Figure 4.30: Comparison of two normal distributions, and histograms for the sampling distribution of the mean for different samples-sizes. The range of sampling distribution of the mean shrinks as sample-size increases
</p>
</div>
<p>Let’s do it again. This time we sample from a flat uniform distribution. Again, we see that the distribution of the sample means is not flat, it looks like a normal distribution.</p>
<div class="figure"><span id="fig:4samplemeanunif"></span>
<img src="quantrma_files/figure-html/4samplemeanunif-1.png" alt="Illustration that the shape of the sampling distribution of the mean is normal, even when the samples come from a non-normal (uniform in this case) distribution" width="672" />
<p class="caption">
Figure 4.31: Illustration that the shape of the sampling distribution of the mean is normal, even when the samples come from a non-normal (uniform in this case) distribution
</p>
</div>
<p>One more time with an exponential distribution. Even though way more of the numbers should be smaller than bigger, then sampling distribution of the mean again does not look the red line. Instead, it looks more normal-ish. That’s the central limit theorem. It just works like that.</p>
<div class="figure"><span id="fig:4samplemeanExp"></span>
<img src="quantrma_files/figure-html/4samplemeanExp-1.png" alt="Illustration that the shape of the sampling distribution of the mean is normal, even when the samples come from a non-normal (exponential in this case) distribution" width="672" />
<p class="caption">
Figure 4.32: Illustration that the shape of the sampling distribution of the mean is normal, even when the samples come from a non-normal (exponential in this case) distribution
</p>
</div>
<p>On the basis of these figures, it seems like we have evidence for all of the following claims about the sampling distribution of the mean:</p>
<ul>
<li><p>The mean of the sampling distribution is the same as the mean of the population</p></li>
<li><p>The standard deviation of the sampling distribution (i.e., the standard error) gets smaller as the sample size increases</p></li>
<li><p>The shape of the sampling distribution becomes normal as the sample size increases</p></li>
</ul>
<p>As it happens, not only are all of these statements true, there is a very famous theorem in statistics that proves all three of them, known as the <strong>central limit theorem</strong>. Among other things, the central limit theorem tells us that if the population distribution has mean <span class="math inline">\(\mu\)</span> and standard deviation <span class="math inline">\(\sigma\)</span>, then the sampling distribution of the mean also has mean <span class="math inline">\(\mu\)</span>, and the standard error of the mean is <span class="math display">\[\mbox{SEM} = \frac{\sigma}{ \sqrt{N} }\]</span> Because we divide the population standard deviation <span class="math inline">\(\sigma\)</span> by the square root of the sample size <span class="math inline">\(N\)</span>, the SEM gets smaller as the sample size increases. It also tells us that the shape of the sampling distribution becomes normal.</p>
<p>This result is useful for all sorts of things. It tells us why large experiments are more reliable than small ones, and because it gives us an explicit formula for the standard error it tells us <strong>how much</strong> more reliable a large experiment is. It tells us why the normal distribution is, well, <strong>normal</strong>. In real experiments, many of the things that we want to measure are actually averages of lots of different quantities (e.g., arguably, “general” intelligence as measured by IQ is an average of a large number of “specific” skills and abilities), and when that happens, the averaged quantity should follow a normal distribution. Because of this mathematical law, the normal distribution pops up over and over again in real data.</p>
</div>
<div id="z-scores" class="section level2">
<h2><span class="header-section-number">4.12</span> z-scores</h2>
<p>We are now in a position to combine some of things we’ve been talking about in this chapter, and introduce you to a new tool, <strong>z-scores</strong>. It turns out we won’t use <strong>z-scores</strong> very much in this textbook. However, you can’t take a class on statistics and not learn about <strong>z-scores</strong>.</p>
<p>The first thing we show you seems to be something that many students remember from their statistics class. This thing is probably remembered because instructors may test this knowledge many times, so students have to learn it for the test. Let’s look at this thing. We are going to look at a normal distribution, and we are going to draw lines through the distribution at 0, +/- 1, +/-2, and +/- 3 standard deviations from the mean:</p>
<div class="figure"><span id="fig:4normalSDspercents"></span>
<img src="quantrma_files/figure-html/4normalSDspercents-1.png" alt="A normal distribution. Each line represents a standard deviation from the mean. The labels show the proportions of scores that fall between each bar." width="672" />
<p class="caption">
Figure 4.33: A normal distribution. Each line represents a standard deviation from the mean. The labels show the proportions of scores that fall between each bar.
</p>
</div>
<p>The figure shows a normal distribution with mean = 0, and standard deviation = 1. We’ve drawn lines at each of the standard deviations: -3, -2, -1, 0, 1, 2, and 3. We also show some numbers in the labels, in between each line. These numbers are proportions. For example, we see the proportion is .341 for scores that fall between the range 0 and 1. Scores between 0 and 1 occur 34.1% of the time. Scores in between -1 and 1, occur 68.2% of the time, that’s more than half of the scores. Scores between 1 and occur about 13.6% of the time, and scores between 2 and 3 occur even less, only 2.1% of the time.</p>
<p>Normal distributions always have these properties, even when they have different means and standard deviations. For example, take a look at this normal distribution, it has a mean =100, and standard deviation =25.</p>
<div class="figure"><span id="fig:4normalSDspercentsB"></span>
<img src="quantrma_files/figure-html/4normalSDspercentsB-1.png" alt="A normal distribution. Each line represents a standard deviation from the mean. The labels show the proportions of scores that fall between each bar." width="672" />
<p class="caption">
Figure 4.34: A normal distribution. Each line represents a standard deviation from the mean. The labels show the proportions of scores that fall between each bar.
</p>
</div>
<p>Now we are looking at a normal distribution with mean = 100 and standard deviation = 25. Notice that the region between 100 and 125 contains 34.1% of the scores. This region is 1 standard deviation away from the mean (the standard deviation is 25, the mean is 100, so 25 is one whole standard deviation away from 100). As you can see, the very same proportions occur between each of the standard deviations, as they did when our standard deviation was set to 1 (with a mean of 0).</p>
<div id="idea-behind-z-scores" class="section level3">
<h3><span class="header-section-number">4.12.1</span> Idea behind z-scores</h3>
<p>Sometimes it can be convenient to transform your original scores into different scores that are easier to work with. For example, if you have a bunch of proportions, like .3, .5, .6, .7, you might want to turn them into percentages like 30%, 50%, 60%, and 70%. To do that you multiply the proportions by a constant of 100. If you want to turn percentages back into proportions, you divide by a constant of 100. This kind of transformation just changes the scale of the numbers from between 0-1, and between 0-100. Otherwise, the pattern in the numbers stays the same.</p>
<p>The idea behind z-scores is a similar kind of transformation. The idea is to express each raw score in terms of it’s standard deviation. For example, if I told you I got a 75% on test, you wouldn’t know how well I did compared to the rest of the class. But, if I told you that I scored 2 standard deviations above the mean, you’d know I did quite well compared to the rest of the class, because you know that most scores (if they are distributed normally) fall below 2 standard deviations of the mean.</p>
<p>We also know, now thanks to the central limit theorem, that many of our measures, such as sample means, will be distributed normally. So, it can often be desirable to express the raw scores in terms of their standard deviations.</p>
<p>Let’s see how this looks in a table without showing you any formulas. We will look at some scores that come from a normal distirbution with mean =100, and standard deviation = 25. We will list some raw scores, along with the z-scores</p>
<table>
<thead>
<tr class="header">
<th align="right">raw</th>
<th align="right">z</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">25</td>
<td align="right">-3</td>
</tr>
<tr class="even">
<td align="right">50</td>
<td align="right">-2</td>
</tr>
<tr class="odd">
<td align="right">75</td>
<td align="right">-1</td>
</tr>
<tr class="even">
<td align="right">100</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="right">125</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="right">150</td>
<td align="right">2</td>
</tr>
<tr class="odd">
<td align="right">175</td>
<td align="right">3</td>
</tr>
</tbody>
</table>
<p>Remember, the mean is 100, and the standard deviation is 25. How many standard deviations away from the mean is a score of 100? The answer is 0, it’s right on the mean. You can see the z-score for 100, is 0. How many standard deviations is 125 away from the mean? Well the standard deviation is 25, 125 is one whole 25 away from 100, that’s a total of 1 standard deviation, so the z-score for 125 is 1. The z-score for 150 is 2, because 150 is two 25s away from 100. The z-score for 50 is -2, because 50 is two 25s away from 100 in the opposite direction. All we are doing here is re-expressing the raw scores in terms of how many standard deviations they are from the mean. Remember, the mean is always right on target, so the center of the z-score distribution is always 0.</p>
</div>
<div id="calculating-z-scores" class="section level3">
<h3><span class="header-section-number">4.12.2</span> Calculating z-scores</h3>
<p>To calculate z-scores all you have to do is figure out how many standard deviations from the mean each number is. Let’s say the mean is 100, and the standard deviation is 25. You have a score of 97. How many standard deviations from the mean is 97?</p>
<p>First compute the difference between the score and the mean:</p>
<p><span class="math inline">\(97-100 = -3\)</span></p>
<p>Alright, we have a total difference of -3. How many standard deviations does -3 represent if 1 standard deviation is 25? Clearly -3 is much smaller than 25, so it’s going to be much less than 1. To figure it out, just divide -3 by the standard deviation.</p>
<p><span class="math inline">\(\frac{-3}{25} = -.12\)</span></p>
<p>Our z-score for 97 is -.12.</p>
<p>Here’s the general formula:</p>
<p><span class="math inline">\(z = \frac{\text{raw score} - \text{mean}}{\text{standard deviation}}\)</span></p>
<p>So, for example if we had these 10 scores from a normal distribution with mean = 100, and standard deviation =25</p>
<pre><code>##  [1]  82.76 115.32  97.49  65.15  89.02 126.95  75.64  77.30  99.46 120.64</code></pre>
<p>The z-scores would be:</p>
<pre><code>##  [1] -0.6896  0.6128 -0.1004 -1.3940 -0.4392  1.0780 -0.9744 -0.9080 -0.0216
## [10]  0.8256</code></pre>
<p>Once you have the z-scores, you could use them as another way to describe your data. For example, now just by looking at a score you know if it is likely or unlikely to occur, because you know how the area under the normal curve works. z-scores between -1 and 1 happen pretty often, scores greater than 1 or -1 still happen fairly often, but not as often. And, scores bigger than 2 or -2 don’t happen very often. This is a convenient thing to do if you want to look at your numbers and get a general sense of how often they happen.</p>
<p>Usually you do not know the mean or the standard deviation of the population that you are drawing your sample scores from. So, you could use the mean and standard deviation of your sample as an estimate, and then use those to calculate z-scores.</p>
<p>Finally, z-scores are also called <strong>standardized scores</strong>, because each raw score is described in terms of it’s standard deviation. This may well be the last time we talk about z-scores in this book. You might wonder why we even bothered telling you about them. First, it’s worth knowing they are a thing. Second, they become important as your statistical prowess becomes more advanced. Third, some statistical concepts, like correlation, can be re-written in terms of z-scores, and this illuminates aspects of those statistics. Finally, they are super useful when you are dealing with a normal distribution that has a known mean and standard deviation.</p>
</div>
</div>
<div id="estimating-population-parameters" class="section level2">
<h2><span class="header-section-number">4.13</span> Estimating population parameters</h2>
<p>Let’s pause for a moment to get our bearings. We’re about to go into the topic of <strong>estimation</strong>. What is that, and why should you care? First, population parameters are things about a distribution. For example, distributions have means. The mean is a parameter of the distribution. The standard deviation of a distribution is a parameter. Anything that can describe a distribution is a potential parameter.</p>
<p>OK fine, who cares? This I think, is a really good question. There are some good concrete reasons to care. And there are some great abstract reasons to care. Unfortunately, most of the time in research, it’s the abstract reasons that matter most, and these can be the most difficult to get your head around.</p>
<div id="concrete-population-parameters" class="section level3">
<h3><span class="header-section-number">4.13.1</span> Concrete population parameters</h3>
<p>First some concrete reasons. There are real populations out there, and sometimes you want to know the parameters of them. For example, if you are a shoe company, you would want to know about the population parameters of feet size. As a first pass, you would want to know the mean and standard deviation of the population. If your company knew this, and other companies did not, your company would do better (assuming all shoes are made equal). Why would your company do better, and how could it use the parameters? Here’s one good reason. As a shoe company you want to meet demand with the right amount of supply. If you make too many big or small shoes, and there aren’t enough people to buy them, then you’re making extra shoes that don’t sell. If you don’t make enough of the most popular sizes, you’ll be leaving money on the table. Right? Yes. So, what would be an optimal thing to do? Perhaps, you would make different amounts of shoes in each size, corresponding to how the demand for each shoe size. You would know something about the demand by figuring out the frequency of each size in the population. You would need to know the population parameters to do this.</p>
<p>Fortunately, it’s pretty easy to get the population parameters without measuring the entire population. Who has time to measure every-bodies feet? Nobody, that’s who. Instead, you would just need to randomly pick a bunch of people, measure their feet, and then measure the parameters of the sample. If you take a big enough sample, we have learned that the sample mean gives a very good estimate of the population mean. We will learn shortly that a version of the standard deviation of the sample also gives a good estimate of the standard deviation of the population. Perhaps shoe-sizes have a slightly different shape than a normal distribution. Here too, if you collect a big enough sample, the shape of the distribution of the sample will be a good estimate of the shape of the populations. All of these are good reasons to care about estimating population parameters. But, do you run a shoe company? Probably not.</p>
</div>
<div id="abstract-population-parameters" class="section level3">
<h3><span class="header-section-number">4.13.2</span> Abstract population parameters</h3>
<p>Even when we think we are talking about something concrete in Psychology, it often gets abstract right away. Instead of measuring the population of feet-sizes, how about the population of human happiness. We all think we know what happiness is, everyone has more or less of it, there are a bunch of people, so there must be a population of happiness right? Perhaps, but it’s not very concrete. The first problem is figuring out how to measure happiness. Let’s use a questionnaire. Consider these questions:</p>
<blockquote>
<p>How happy are you right now on a scale from 1 to 7?
How happy are you in general on a scale from 1 to 7?
How happy are you in the mornings on a scale from 1 to 7?
How happy are you in the afternoons on a scale from 1 to 7?</p>
</blockquote>
<ol style="list-style-type: decimal">
<li>= very unhappy</li>
<li>= unhappy</li>
<li>= sort of unhappy</li>
<li>= in the middle</li>
<li>= sort of happy</li>
<li>= happy</li>
<li>= very happy</li>
</ol>
<p>Forget about asking these questions to everybody in the world. Let’s just ask them to lots of people (our sample). What do you think would happen? Well, obviously people would give all sorts of answers right. We could tally up the answers and plot them in a histogram. This would show us a distribution of happiness scores from our sample. “Great, fantastic!”, you say. Yes, fine and dandy.</p>
<p>So, on the one hand we could say lots of things about the people in our sample. We could say exactly who says they are happy and who says they aren’t, after all they just told us!</p>
<p>But, what can we say about the larger population? Can we use the parameters of our sample (e.g., mean, standard deviation, shape etc.) to estimate something about a larger population. Can we infer how happy everybody else is, just from our sample? HOLD THE PHONE.</p>
<div id="complications-with-inference" class="section level4">
<h4><span class="header-section-number">4.13.2.1</span> Complications with inference</h4>
<p>Before listing a bunch of complications, let me tell you what I think we can do with our sample. Provided it is big enough, our sample parameters will be a pretty good estimate of what another sample would look like. Because of the following discussion, this is often all we can say. But, that’s OK, as you see throughout this book, we can work with that!</p>
<p><strong>Problem 1: Multiple populations</strong>: If you looked at a large sample of questionnaire data you will find evidence of multiple distributions inside your sample. People answer questions differently. Some people are very cautious and not very extreme. Their answers will tend to be distributed about the middle of the scale, mostly 3s, 4s, and 5s. Some people are very bi-modal, they are very happy and very unhappy, depending on time of day. These people’s answers will be mostly 1s and 2s, and 6s and 7s, and those numbers look like they come from a completely different distribution. Some people are entirely happy or entirely unhappy. Again, these two “populations” of people’s numbers look like two different distributions, one with mostly 6s and 7s, and one with mostly 1s and 2s. Other people will be more random, and their scores will look like a uniform distribution. So, is there a single population with parameters that we can estimate from our sample? Probably not. Could be a mixture of lots of populations with different distributions.</p>
<p><strong>Problem 2: What do these questions measure?</strong>: If the whole point of doing the questionnaire is to estimate the population’s happiness, we really need wonder if the sample measurements actually tell us anything about happiness in the first place. Some questions: Are people accurate in saying how happy they are? Does the measure of happiness depend on the scale, for example, would the results be different if we used 0-100, or -100 to +100, or no numbers? Does the measure of happiness depend on the wording in the question? Does a measure like this one tell us everything we want to know about happiness (probably not), what is it missing (who knows? probably lots). In short, nobody knows if these kinds of questions measure what we want them to measure. We just hope that they do. Instead, we have a very good idea of the kinds of things that they actually measure. It’s really quite obvious, and staring you in the face. Questionnaire measurements measure how people answer questionnaires. In other words, how people behave and answer questions when they are given a questionnaire. This might also measure something about happiness, when the question has to do about happiness. But, it turns out people are remarkably consistent in how they answer questions, even when the questions are total nonsense, or have no questions at all (just numbers to choose!) <span class="citation">Maul (<a href="#ref-maul_rethinking_2017" role="doc-biblioref">2017</a>)</span>.</p>
<p>The take home complications here are that we can collect samples, but in Psychology, we often don’t have a good idea of the populations that might be linked to these samples. There might be lots of populations, or the populations could be different depending on who you ask. Finally, the “population” might not be the one you want it to be.</p>
</div>
</div>
<div id="experiments-and-population-parameters" class="section level3">
<h3><span class="header-section-number">4.13.3</span> Experiments and Population parameters</h3>
<p>OK, so we don’t own a shoe company, and we can’t really identify the population of interest in Psychology, can’t we just skip this section on estimation? After all, the “population” is just too weird and abstract and useless and contentious. HOLD THE PHONE AGAIN!</p>
<p>It turns out we can apply the things we have been learning to solve lots of important problems in research. These allow us to answer questions with the data that we collect. Parameter estimation is one of these tools. We just need to be a little bit more creative, and a little bit more abstract to use the tools.</p>
<p>Here is what we know already. The numbers that we measure come from somewhere, we have called this place “distributions”. Distributions control how the numbers arrive. Some numbers happen more than others depending on the distribution. We assume, even if we don’t know what the distribution is, or what it means, that the numbers came from one. Second, when get some numbers, we call it a sample. This entire chapter so far has taught you one thing. When your sample is big, it resembles the distribution it came from. And, when your sample is big, it will resemble very closely what another big sample of the same thing will look like. We can use this knowledge!</p>
<p>Very often as Psychologists what we want to know is what causes what. We want to know if X causes something to change in Y. Does eating chocolate make you happier? Does studying improve your grades? There a bazillions of these kinds of questions. And, we want answers to them.</p>
<p>I’ve been trying to be mostly concrete so far in this textbook, that’s why we talk about silly things like chocolate and happiness, at least they are concrete. Let’s give a go at being abstract. We can do it.</p>
<p>So, we want to know if X causes Y to change. What is X? What is Y? X is something you change, something you manipulate, the independent variable. Y is something you measure. So, we will be taking samples from Y. “Oh I get it, we’ll take samples from Y, then we can use the sample parameters to estimate the population parameters of Y!” NO, not really, but yes sort of. We will take sample from Y, that is something we absolutely do. In fact, that is really all we ever do, which is why talking about the population of Y is kind of meaningless. We’re more interested in our samples of Y, and how they behave.</p>
<p>So, what would happen if we removed X from the universe altogether, and then took a big sample of Y. We’ll pretend Y measures something in a Psychology experiment. So, we know right away that Y is variable. When we take a big sample, it will have a distribution (because Y is variable). So, we can do things like measure the mean of Y, and measure the standard deviation of Y, and anything else we want to know about Y. Fine. What would happen if we replicated this measurement. That is, we just take another random sample of Y, just as big as the first. What should happen is that our first sample should look a lot like our second example. After all, we didn’t do anything to Y, we just took two big samples twice. Both of our samples will be a little bit different (due to sampling error), but they’ll be mostly the same. The bigger our samples, the more they will look the same, especially when we don’t do anything to cause them to be different. In other words, we can use the parameters of one sample to estimate the parameters of a second sample, because they will tend to be the same, especially when they are large.</p>
<p>We are now ready for step two. You want to know if X changes Y. What do you do? You make X go up and take a big sample of Y then look at it. You make X go down, then take a second big sample of Y and look at it. Next, you compare the two samples of Y. If X does nothing then what should you find? We already discussed that in the previous paragraph. If X does nothing, then both of your big samples of Y should be pretty similar. However, if X does something to Y, then one of your big samples of Y will be different from the other. You will have changed something about Y. Maybe X makes the mean of Y change. Or maybe X makes the variation in Y change. Or, maybe X makes the whole shape of the distribution change. If we find any big changes that can’t be explained by sampling error, then we can conclude that something about X caused a change in Y! We could use this approach to learn about what causes what!</p>
<p>The very important idea is still about estimation, just not population parameter estimation exactly. We know that when we take samples they naturally vary. So, when we estimate a parameter of a sample, like the mean, we know we are off by some amount. When we find that two samples are different, we need to find out if the size of the difference is consistent with what sampling error can produce, or if the difference is bigger than that. If the difference is bigger, then we can be confident that sampling error didn’t produce the difference. So, we can confidently infer that something else (like an X) did cause the difference. This bit of abstract thinking is what most of the rest of the textbook is about. Determining whether there is a difference caused by your manipulation. There’s more to the story, there always is. We can get more specific than just, is there a difference, but for introductory purposes, we will focus on the finding of differences as a foundational concept.</p>
</div>
<div id="interim-summary" class="section level3">
<h3><span class="header-section-number">4.13.4</span> Interim summary</h3>
<p>We’ve talked about estimation without doing any estimation, so in the next section we will do some estimating of the mean and of the standard deviation. Formally, we talk about this as using a sample to estimate a parameter of the population. Feel free to think of the “population” in different ways. It could be concrete population, like the distribution of feet-sizes. Or, it could be something more abstract, like the parameter estimate of what samples usually look like when they come from a distribution.</p>
</div>
<div id="estimating-the-population-mean" class="section level3">
<h3><span class="header-section-number">4.13.5</span> Estimating the population mean</h3>
<p>Suppose we go to Brooklyn and 100 of the locals are kind enough to sit through an IQ test. The average IQ score among these people turns out to be <span class="math inline">\(\bar{X}=98.5\)</span>. So what is the true mean IQ for the entire population of Brooklyn? Obviously, we don’t know the answer to that question. It could be <span class="math inline">\(97.2\)</span>, but if could also be <span class="math inline">\(103.5\)</span>. Our sampling isn’t exhaustive so we cannot give a definitive answer. Nevertheless if forced to give a “best guess” I’d have to say <span class="math inline">\(98.5\)</span>. That’s the essence of statistical estimation: giving a best guess. We’re using the sample mean as the best guess of the population mean.</p>
<p>In this example, estimating the unknown population parameter is straightforward. I calculate the sample mean, and I use that as my <strong>estimate of the population mean</strong>. It’s pretty simple, and in the next section we’ll explain the statistical justification for this intuitive answer. However, for the moment let’s make sure you recognize that the sample statistic and the estimate of the population parameter are conceptually different things. A sample statistic is a description of your data, whereas the estimate is a guess about the population. With that in mind, statisticians often use different notation to refer to them. For instance, if true population mean is denoted <span class="math inline">\(\mu\)</span>, then we would use <span class="math inline">\(\hat\mu\)</span> to refer to our estimate of the population mean. In contrast, the sample mean is denoted <span class="math inline">\(\bar{X}\)</span> or sometimes <span class="math inline">\(m\)</span>. However, in simple random samples, the estimate of the population mean is identical to the sample mean: if I observe a sample mean of <span class="math inline">\(\bar{X} = 98.5\)</span>, then my estimate of the population mean is also <span class="math inline">\(\hat\mu = 98.5\)</span>. To help keep the notation clear, here’s a handy table:</p>
<table>
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<thead>
<tr class="header">
<th>Symbol</th>
<th>What is it?</th>
<th>Do we know what it is?</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(\bar{X}\)</span></td>
<td>Sample mean</td>
<td>Yes, calculated from the raw data</td>
</tr>
<tr class="even">
<td><span class="math inline">\(\mu\)</span></td>
<td>True population mean</td>
<td>Almost never known for sure</td>
</tr>
<tr class="odd">
<td><span class="math inline">\(\hat{\mu}\)</span></td>
<td>Estimate of the population mean</td>
<td>Yes, identical to the sample mean</td>
</tr>
</tbody>
</table>
</div>
<div id="estimating-the-population-standard-deviation" class="section level3">
<h3><span class="header-section-number">4.13.6</span> Estimating the population standard deviation</h3>
<p>So far, estimation seems pretty simple, and you might be wondering why I forced you to read through all that stuff about sampling theory. In the case of the mean, our estimate of the population parameter (i.e. <span class="math inline">\(\hat\mu\)</span>) turned out to identical to the corresponding sample statistic (i.e. <span class="math inline">\(\bar{X}\)</span>). However, that’s not always true. To see this, let’s have a think about how to construct an <strong>estimate of the population standard deviation</strong>, which we’ll denote <span class="math inline">\(\hat\sigma\)</span>. What shall we use as our estimate in this case? Your first thought might be that we could do the same thing we did when estimating the mean, and just use the sample statistic as our estimate. That’s almost the right thing to do, but not quite.</p>
<p>Here’s why. Suppose I have a sample that contains a single observation. For this example, it helps to consider a sample where you have no intuitions at all about what the true population values might be, so let’s use something completely fictitious. Suppose the observation in question measures the <strong>cromulence</strong> of my shoes. It turns out that my shoes have a cromulence of 20. So here’s my sample:</p>
<p><code>20</code></p>
<p>This is a perfectly legitimate sample, even if it does have a sample size of <span class="math inline">\(N=1\)</span>. It has a sample mean of 20, and because every observation in this sample is equal to the sample mean (obviously!) it has a sample standard deviation of 0. As a description of the <strong>sample</strong> this seems quite right: the sample contains a single observation and therefore there is no variation observed within the sample. A sample standard deviation of <span class="math inline">\(s = 0\)</span> is the right answer here. But as an estimate of the <strong>population</strong> standard deviation, it feels completely insane, right? Admittedly, you and I don’t know anything at all about what “cromulence” is, but we know something about data: the only reason that we don’t see any variability in the <strong>sample</strong> is that the sample is too small to display any variation! So, if you have a sample size of <span class="math inline">\(N=1\)</span>, it <strong>feels</strong> like the right answer is just to say “no idea at all”.</p>
<p>Notice that you <strong>don’t</strong> have the same intuition when it comes to the sample mean and the population mean. If forced to make a best guess about the population mean, it doesn’t feel completely insane to guess that the population mean is 20. Sure, you probably wouldn’t feel very confident in that guess, because you have only the one observation to work with, but it’s still the best guess you can make.</p>
<p>Let’s extend this example a little. Suppose I now make a second observation. My data set now has <span class="math inline">\(N=2\)</span> observations of the cromulence of shoes, and the complete sample now looks like this:</p>
<p><code>20, 22</code></p>
<p>This time around, our sample is <strong>just</strong> large enough for us to be able to observe some variability: two observations is the bare minimum number needed for any variability to be observed! For our new data set, the sample mean is <span class="math inline">\(\bar{X}=21\)</span>, and the sample standard deviation is <span class="math inline">\(s=1\)</span>. What intuitions do we have about the population? Again, as far as the population mean goes, the best guess we can possibly make is the sample mean: if forced to guess, we’d probably guess that the population mean cromulence is 21. What about the standard deviation? This is a little more complicated. The sample standard deviation is only based on two observations, and if you’re at all like me you probably have the intuition that, with only two observations, we haven’t given the population “enough of a chance” to reveal its true variability to us. It’s not just that we suspect that the estimate is <strong>wrong</strong>: after all, with only two observations we expect it to be wrong to some degree. The worry is that the error is <strong>systematic</strong>.</p>
<p>If the error is systematic, that means it is <strong>biased</strong>. For example, imagine if the sample mean was always smaller than the population mean. If this was true (it’s not), then we couldn’t use the sample mean as an estimator. It would be biased, we’d be using the wrong number.</p>
<p>It turns out the sample standard deviation is a <strong>biased estimator</strong> of the population standard deviation. We can sort of anticipate this by what we’ve been discussing. When the sample size is 1, the standard deviation is 0, which is obviously to small. When the sample size is 2, the standard deviation becomes a number bigger than 0, but because we only have two sample, we suspect it might still be too small. Turns out this intuition is correct.</p>
<p>It would be nice to demonstrate this somehow. There are in fact mathematical proofs that confirm this intuition, but unless you have the right mathematical background they don’t help very much. Instead, what I’ll do is use R to simulate the results of some experiments. With that in mind, let’s return to our IQ studies. Suppose the true population mean IQ is 100 and the standard deviation is 15. I can use the <strong>rnorm()</strong> function to generate the the results of an experiment in which I measure <span class="math inline">\(N=2\)</span> IQ scores, and calculate the sample standard deviation. If I do this over and over again, and plot a histogram of these sample standard deviations, what I have is the <strong>sampling distribution of the standard deviation</strong>. I’ve plotted this distribution in Figure <a href="week-4-probability-sampling-and-estimation.html#fig:sampdistsd">4.35</a>.</p>
<div class="figure"><span id="fig:sampdistsd"></span>
<img src="figures/estimation/sampdistsd.pdf" alt="The sampling distribution of the sample standard deviation for a two IQ scores experiment. The true population standard deviation is 15 (dashed line), but as you can see from the histogram, the vast majority of experiments will produce a much smaller sample standard deviation than this. On average, this experiment would produce a sample standard deviation of only 8.5, well below the true value! In other words, the sample standard deviation is a biased estimate of the population standard deviation."  />
<p class="caption">
Figure 4.35: The sampling distribution of the sample standard deviation for a two IQ scores experiment. The true population standard deviation is 15 (dashed line), but as you can see from the histogram, the vast majority of experiments will produce a much smaller sample standard deviation than this. On average, this experiment would produce a sample standard deviation of only 8.5, well below the true value! In other words, the sample standard deviation is a biased estimate of the population standard deviation.
</p>
</div>
<p>Even though the true population standard deviation is 15, the average of the <strong>sample</strong> standard deviations is only 8.5. Notice that this is a very different from when we were plotting sampling distributions of the sample mean, those were always centered around the mean of the population.</p>
<p>Now let’s extend the simulation. Instead of restricting ourselves to the situation where we have a sample size of <span class="math inline">\(N=2\)</span>, let’s repeat the exercise for sample sizes from 1 to 10. If we plot the average sample mean and average sample standard deviation as a function of sample size, you get the following results.</p>
<p>Figure <a href="week-4-probability-sampling-and-estimation.html#fig:estimatorbiasA">4.36</a> shows the sample mean as a function of sample size. Notice it’s a flat line. The sample mean doesn’t underestimate or overestimate the population mean. It is an unbiased estimate!</p>
<div class="figure"><span id="fig:estimatorbiasA"></span>
<img src="figures/estimation/biasMean-eps-converted-to.pdf" alt="An illustration of the fact that the sample mean is an unbiased estimator of the population mean."  />
<p class="caption">
Figure 4.36: An illustration of the fact that the sample mean is an unbiased estimator of the population mean.
</p>
</div>
<p>Figure <a href="week-4-probability-sampling-and-estimation.html#fig:estimatorbiasB">4.37</a> shows the sample standard deviation as a function of sample size. Notice it is not a flat line. The sample standard deviation systematically underestimates the population standard deviation!</p>
<div class="figure"><span id="fig:estimatorbiasB"></span>
<img src="figures/estimation/biasSD-eps-converted-to.pdf" alt="An illustration of the fact that the the sample standard deviation is a biased estimator of the population standard deviation"  />
<p class="caption">
Figure 4.37: An illustration of the fact that the the sample standard deviation is a biased estimator of the population standard deviation
</p>
</div>
<p>In other words, if we want to make a “best guess” (<span class="math inline">\(\hat\sigma\)</span>, our estimate of the population standard deviation) about the value of the population standard deviation <span class="math inline">\(\sigma\)</span>, we should make sure our guess is a little bit larger than the sample standard deviation <span class="math inline">\(s\)</span>.</p>
<p>The fix to this systematic bias turns out to be very simple. Here’s how it works. Before tackling the standard deviation, let’s look at the variance. If you recall from the second chapter, the sample variance is defined to be the average of the squared deviations from the sample mean. That is: <span class="math display">\[s^2 = \frac{1}{N} \sum_{i=1}^N (X_i - \bar{X})^2\]</span> The sample variance <span class="math inline">\(s^2\)</span> is a biased estimator of the population variance <span class="math inline">\(\sigma^2\)</span>. But as it turns out, we only need to make a tiny tweak to transform this into an unbiased estimator. All we have to do is divide by <span class="math inline">\(N-1\)</span> rather than by <span class="math inline">\(N\)</span>. If we do that, we obtain the following formula: <span class="math display">\[\hat\sigma^2 = \frac{1}{N-1} \sum_{i=1}^N (X_i - \bar{X})^2\]</span> This is an unbiased estimator of the population variance <span class="math inline">\(\sigma\)</span>.</p>
<p>A similar story applies for the standard deviation. If we divide by <span class="math inline">\(N-1\)</span> rather than <span class="math inline">\(N\)</span>, our estimate of the population standard deviation becomes: <span class="math display">\[\hat\sigma = \sqrt{\frac{1}{N-1} \sum_{i=1}^N (X_i - \bar{X})^2}\]</span>.</p>
<p>It is worth pointing out that software programs make assumptions <strong>for you</strong>, about which variance and standard deviation <strong>you</strong> are computing. Some programs automatically divide by <span class="math inline">\(N-1\)</span>, some do not. You need to check to figure out what they are doing. Don’t let the software tell you what to do. Software is for you telling it what to do.</p>
<p>One final point: in practice, a lot of people tend to refer to <span class="math inline">\(\hat{\sigma}\)</span> (i.e., the formula where we divide by <span class="math inline">\(N-1\)</span>) as the <strong>sample</strong> standard deviation. Technically, this is incorrect: the <strong>sample</strong> standard deviation should be equal to <span class="math inline">\(s\)</span> (i.e., the formula where we divide by <span class="math inline">\(N\)</span>). These aren’t the same thing, either conceptually or numerically. One is a property of the sample, the other is an estimated characteristic of the population. However, in almost every real life application, what we actually care about is the estimate of the population parameter, and so people always report <span class="math inline">\(\hat\sigma\)</span> rather than <span class="math inline">\(s\)</span>.</p>
<div class="marginnote">
<p>Note, whether you should divide by N or N-1 also depends on your philosophy about what you are doing. For example, if you don’t think that what you are doing is estimating a population parameter, then why would you divide by N-1? Also, when N is large, it doesn’t matter too much. The difference between a big N, and a big N-1, is just -1.</p>
</div>
<p>This is the right number to report, of course, it’s that people tend to get a little bit imprecise about terminology when they write it up, because “sample standard deviation” is shorter than “estimated population standard deviation”. It’s no big deal, and in practice I do the same thing everyone else does. Nevertheless, I think it’s important to keep the two <strong>concepts</strong> separate: it’s never a good idea to confuse “known properties of your sample” with “guesses about the population from which it came”. The moment you start thinking that <span class="math inline">\(s\)</span> and <span class="math inline">\(\hat\sigma\)</span> are the same thing, you start doing exactly that.</p>
<p>To finish this section off, here’s another couple of tables to help keep things clear:</p>
<table>
<colgroup>
<col width="29%" />
<col width="35%" />
<col width="35%" />
</colgroup>
<thead>
<tr class="header">
<th>Symbol</th>
<th>What is it?</th>
<th>Do we know what it is?</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(s^2\)</span></td>
<td>Sample variance</td>
<td>Yes, calculated from the raw data</td>
</tr>
<tr class="even">
<td><span class="math inline">\(\sigma^2\)</span></td>
<td>Population variance</td>
<td>Almost never known for sure</td>
</tr>
<tr class="odd">
<td><span class="math inline">\(\hat{\sigma}^2\)</span></td>
<td>Estimate of the population variance</td>
<td>Yes, but not the same as the sample variance</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="estimating-a-confidence-interval" class="section level2">
<h2><span class="header-section-number">4.14</span> Estimating a confidence interval</h2>
<blockquote>
<p>Statistics means never having to say you’re certain – Unknown origin</p>
</blockquote>
<p>Up to this point in this chapter, we’ve outlined the basics of sampling theory which statisticians rely on to make guesses about population parameters on the basis of a sample of data. As this discussion illustrates, one of the reasons we need all this sampling theory is that every data set leaves us with some of uncertainty, so our estimates are never going to be perfectly accurate. The thing that has been missing from this discussion is an attempt to <strong>quantify</strong> the amount of uncertainty in our estimate. It’s not enough to be able guess that the mean IQ of undergraduate psychology students is 115 (yes, I just made that number up). We also want to be able to say something that expresses the degree of certainty that we have in our guess. For example, it would be nice to be able to say that there is a 95% chance that the true mean lies between 109 and 121. The name for this is a <strong>confidence interval</strong> for the mean.</p>
<p>Armed with an understanding of sampling distributions, constructing a confidence interval for the mean is actually pretty easy. Here’s how it works. Suppose the true population mean is <span class="math inline">\(\mu\)</span> and the standard deviation is <span class="math inline">\(\sigma\)</span>. I’ve just finished running my study that has <span class="math inline">\(N\)</span> participants, and the mean IQ among those participants is <span class="math inline">\(\bar{X}\)</span>. We know from our discussion of the central limit theorem that the sampling distribution of the mean is approximately normal. We also know from our discussion of the normal distribution that there is a 95% chance that a normally-distributed quantity will fall within two standard deviations of the true mean. To be more precise, we can use the <strong>qnorm()</strong> function to compute the 2.5th and 97.5th percentiles of the normal distribution</p>
<blockquote>
<p>qnorm( p = c(.025, .975) ) [1] -1.959964 1.959964</p>
</blockquote>
<p>Okay, so I lied earlier on. The more correct answer is that a 95% chance that a normally-distributed quantity will fall within 1.96 standard deviations of the true mean.</p>
<p>Next, recall that the standard deviation of the sampling distribution is referred to as the standard error, and the standard error of the mean is written as SEM. When we put all these pieces together, we learn that there is a 95% probability that the sample mean <span class="math inline">\(\bar{X}\)</span> that we have actually observed lies within 1.96 standard errors of the population mean. Oof, that is a lot of mathy talk there. We’ll clear it up, don’t worry.</p>
<p>Mathematically, we write this as: <span class="math display">\[\mu - \left( 1.96 \times \mbox{SEM} \right) \ \leq \  \bar{X}\  \leq \  \mu + \left( 1.96 \times \mbox{SEM} \right)\]</span> where the SEM is equal to <span class="math inline">\(\sigma / \sqrt{N}\)</span>, and we can be 95% confident that this is true.</p>
<p>However, that’s not answering the question that we’re actually interested in. The equation above tells us what we should expect about the sample mean, given that we know what the population parameters are. What we <strong>want</strong> is to have this work the other way around: we want to know what we should believe about the population parameters, given that we have observed a particular sample. However, it’s not too difficult to do this. Using a little high school algebra, a sneaky way to rewrite our equation is like this: <span class="math display">\[\bar{X} -  \left( 1.96 \times \mbox{SEM} \right) \ \leq \ \mu  \ \leq  \ \bar{X} +  \left( 1.96 \times \mbox{SEM}\right)\]</span> What this is telling is is that the range of values has a 95% probability of containing the population mean <span class="math inline">\(\mu\)</span>. We refer to this range as a <strong>95% confidence interval</strong>, denoted <span class="math inline">\(\mbox{CI}_{95}\)</span>. In short, as long as <span class="math inline">\(N\)</span> is sufficiently large – large enough for us to believe that the sampling distribution of the mean is normal – then we can write this as our formula for the 95% confidence interval: <span class="math display">\[\mbox{CI}_{95} = \bar{X} \pm \left( 1.96 \times \frac{\sigma}{\sqrt{N}} \right)\]</span> Of course, there’s nothing special about the number 1.96: it just happens to be the multiplier you need to use if you want a 95% confidence interval. If I’d wanted a 70% confidence interval, I could have used the <strong>qnorm()</strong> function to calculate the 15th and 85th quantiles:</p>
<blockquote>
<p>qnorm( p = c(.15, .85) ) [1] -1.036433 1.036433</p>
</blockquote>
<p>and so the formula for <span class="math inline">\(\mbox{CI}_{70}\)</span> would be the same as the formula for <span class="math inline">\(\mbox{CI}_{95}\)</span> except that we’d use 1.04 as our magic number rather than 1.96.</p>
<div id="a-slight-mistake-in-the-formula" class="section level3">
<h3><span class="header-section-number">4.14.1</span> A slight mistake in the formula</h3>
<p>As usual, I lied. The formula that I’ve given above for the 95% confidence interval is approximately correct, but I glossed over an important detail in the discussion. Notice my formula requires you to use the standard error of the mean, SEM, which in turn requires you to use the true population standard deviation <span class="math inline">\(\sigma\)</span>.</p>
<p>Yet, before we stressed the fact that we don’t actually <strong>know</strong> the true population parameters. Because we don’t know the true value of <span class="math inline">\(\sigma\)</span>, we have to use an estimate of the population standard deviation <span class="math inline">\(\hat{\sigma}\)</span> instead. This is pretty straightforward to do, but this has the consequence that we need to use the quantiles of the <span class="math inline">\(t\)</span>-distribution rather than the normal distribution to calculate our magic number; and the answer depends on the sample size. Plus, we haven’t really talked about the <span class="math inline">\(t\)</span> distribution yet.</p>
<p>When we use the <span class="math inline">\(t\)</span> distribution instead of the normal distribution, we get bigger numbers, indicating that we have more uncertainty. And why do we have that extra uncertainty? Well, because our estimate of the population standard deviation <span class="math inline">\(\hat\sigma\)</span> might be wrong! If it’s wrong, it implies that we’re a bit less sure about what our sampling distribution of the mean actually looks like… and this uncertainty ends up getting reflected in a wider confidence interval.</p>

</div>
</div>
</div>
<h3> References</h3>
<div id="refs" class="references">
<div id="ref-fisher_interpretation_1922">
<p>Fisher, R. A. 1922. “On the Interpretation of Chi-Squared from Contingency Tables, and the Calculation of P.” <em>Journal of the Royal Statistical Society</em> 84: 87–94.</p>
</div>
<div id="ref-keynes_tract_1923">
<p>Keynes, John Maynard. 1923. <em>A Tract on Monetary Reform</em>. London: Macmillan; Company.</p>
</div>
<div id="ref-maul_rethinking_2017">
<p>Maul, Andrew. 2017. “Rethinking Traditional Methods of Survey Validation.” <em>Measurement: Interdisciplinary Research and Perspectives</em> 15 (2): 51–69. <a href="https://doi.org/10.1080/15366367.2017.1348108">https://doi.org/10.1080/15366367.2017.1348108</a>.</p>
</div>
<div id="ref-meehl_theory_1967">
<p>Meehl, P. H. 1967. “Theory Testing in Psychology and Physics: A Methodological Paradox.” <em>Philosophy of Science</em> 34: 103–15.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="13">
<li id="fn13"><p>Mix of Matthew Crump &amp; Danielle Navarro<a href="week-4-probability-sampling-and-estimation.html#fnref13" class="footnote-back">↩︎</a></p></li>
<li id="fn14"><p>We did something <a href="week-3-correlation-and-causation-adapted3.html#corrform">similar last week</a>, but I didn’t show the code.<a href="week-4-probability-sampling-and-estimation.html#fnref14" class="footnote-back">↩︎</a></p></li>
<li id="fn15"><p>See <a href="https://www.tylervigen.com/spurious-correlations">this website</a> by Tyler Vigen for some interesting spurious correlations. You can even use his website to <a href="https://tylervigen.com/discover">discover a spurious correlation</a> of your own!<a href="week-4-probability-sampling-and-estimation.html#fnref15" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="week-3-correlation-and-causation-adapted3.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="references.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
